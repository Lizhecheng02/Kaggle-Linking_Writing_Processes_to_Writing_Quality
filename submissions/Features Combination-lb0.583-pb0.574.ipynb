{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2fbc1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T05:56:36.380080Z",
     "iopub.status.busy": "2024-01-09T05:56:36.379662Z",
     "iopub.status.idle": "2024-01-09T05:56:44.561073Z",
     "shell.execute_reply": "2024-01-09T05:56:44.560107Z"
    },
    "papermill": {
     "duration": 8.191671,
     "end_time": "2024-01-09T05:56:44.563422",
     "exception": false,
     "start_time": "2024-01-09T05:56:36.371751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "from sklearn import metrics, model_selection\n",
    "from collections import defaultdict, Counter\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import optuna\n",
    "from scipy.stats import skew, kurtosis\n",
    "import warnings\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f6c1f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T05:56:44.576984Z",
     "iopub.status.busy": "2024-01-09T05:56:44.576703Z",
     "iopub.status.idle": "2024-01-09T05:56:44.636194Z",
     "shell.execute_reply": "2024-01-09T05:56:44.635457Z"
    },
    "papermill": {
     "duration": 0.068501,
     "end_time": "2024-01-09T05:56:44.637990",
     "exception": false,
     "start_time": "2024-01-09T05:56:44.569489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kurtosis_func(x): return x.kurt()\n",
    "\n",
    "\n",
    "def q1(x):\n",
    "    return x.quantile(0.25)\n",
    "\n",
    "\n",
    "def q3(x):\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, seed):\n",
    "        self.seed = seed\n",
    "\n",
    "        self.activities = ['Input', 'Remove/Cut',\n",
    "                           'Nonproduction', 'Replace', 'Paste']\n",
    "\n",
    "        self.events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft',\n",
    "                       'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', 'Delete', 'Unidentified']\n",
    "\n",
    "        self.events2 = ['q', 'Space', 'Backspace']\n",
    "\n",
    "        self.text_changes = ['q', ' ', 'NoChange', '.', ',', '\\n', \"'\",\n",
    "                             '\"', '-', '?', ';', '=', '/', '\\\\', ':']\n",
    "\n",
    "        # self.text_changes = ['q', ' ', 'NoChange', ',']\n",
    "\n",
    "        self.punctuations = ['\"', '.', ',', \"'\", '-', ';', ':', '?', '!', '<', '>', '/',\n",
    "                             '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+', '`', '~',\n",
    "                             '|', '!', '\\\\']\n",
    "\n",
    "        self.gaps = [1, 15, 50, 100]\n",
    "\n",
    "        self.idf = defaultdict(float)\n",
    "\n",
    "        self.device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "\n",
    "    def activity_counts(self, df):\n",
    "        tmp_df = df.groupby('id').agg({'activity': list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tqdm(tmp_df['activity'].values):\n",
    "            items = list(Counter(li).items())\n",
    "            di = dict()\n",
    "            for k in self.activities:\n",
    "                di[k] = 0\n",
    "#             di[\"Move\"] = 0\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in di:\n",
    "                    di[k] = v\n",
    "#                 else:\n",
    "#                     di[\"Move\"] += v\n",
    "            ret.append(di)\n",
    "        ret = pd.DataFrame(ret)\n",
    "        cols = [f'activity_{i}_count' for i in range(len(ret.columns))]\n",
    "        ret.columns = cols\n",
    "\n",
    "        cnts = ret.sum(1)\n",
    "        epsilon = 1e-15\n",
    "\n",
    "        for col in cols:\n",
    "            if col in self.idf.keys():\n",
    "                idf = self.idf[col]\n",
    "            else:\n",
    "                idf = df.shape[0] / (ret[col].sum() + 1)\n",
    "                idf = np.log(idf)\n",
    "                self.idf[col] = idf\n",
    "\n",
    "            ret[col] = 1 + np.log((ret[col] + epsilon) / (cnts + epsilon))\n",
    "            ret[col] *= idf\n",
    "\n",
    "        # cnts = ret.sum(axis=1)\n",
    "        # for col in cols:\n",
    "        #     ret[col] = ret[col] / cnts\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def match_punctuations(self, df):\n",
    "        tmp_df = df.groupby('id').agg({'down_event': list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tqdm(tmp_df['down_event'].values):\n",
    "            cnt = 0\n",
    "            items = list(Counter(li).items())\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in self.punctuations:\n",
    "                    cnt += v\n",
    "            ret.append(cnt)\n",
    "        ret = pd.DataFrame({'punct_cnt': ret})\n",
    "        return ret\n",
    "\n",
    "    def text_change_counts(self, df):\n",
    "        tmp_df = df.groupby('id').agg({'text_change': list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tqdm(tmp_df['text_change'].values):\n",
    "            items = list(Counter(li).items())\n",
    "            di = dict()\n",
    "            for k in self.text_changes:\n",
    "                di[k] = 0\n",
    "#             di['Change'] = 0\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in di:\n",
    "                    di[k] = v\n",
    "                elif k.find('q') != -1 and not k.find('=>') != -1:\n",
    "                    di['q'] += v\n",
    "#                 elif k.find('=>') != -1:\n",
    "#                     di['Change'] += v\n",
    "            ret.append(di)\n",
    "        ret = pd.DataFrame(ret)\n",
    "        cols = [f'text_change_{i}_count' for i in range(len(ret.columns))]\n",
    "        ret.columns = cols\n",
    "\n",
    "        cnts = ret.sum(1)\n",
    "        epsilon = 1e-15\n",
    "\n",
    "        for col in cols:\n",
    "            if col in self.idf.keys():\n",
    "                idf = self.idf[col]\n",
    "            else:\n",
    "                idf = df.shape[0] / (ret[col].sum() + 1)\n",
    "                idf = np.log(idf)\n",
    "                self.idf[col] = idf\n",
    "\n",
    "            ret[col] = 1 + np.log((ret[col] + epsilon) / (cnts + epsilon))\n",
    "            ret[col] *= idf\n",
    "\n",
    "        # cnts = ret.sum(axis=1)\n",
    "        # for col in cols:\n",
    "        #     ret[col] = ret[col] / cnts\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def event_counts(self, df, colname):\n",
    "        tmp_df = df.groupby('id').agg({colname: list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tqdm(tmp_df[colname].values):\n",
    "            items = list(Counter(li).items())\n",
    "            di = dict()\n",
    "            for k in self.events:\n",
    "                di[k] = 0\n",
    "#             di['Other'] = 0\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in di:\n",
    "                    di[k] = v\n",
    "#                 else:\n",
    "#                     di['Other'] += v\n",
    "            ret.append(di)\n",
    "        ret = pd.DataFrame(ret)\n",
    "        cols = [f'{colname}_{i}_count' for i in range(len(ret.columns))]\n",
    "        ret.columns = cols\n",
    "\n",
    "        cnts = ret.sum(1)\n",
    "        epsilon = 1e-15\n",
    "\n",
    "        for col in cols:\n",
    "            if col in self.idf.keys():\n",
    "                idf = self.idf[col]\n",
    "            else:\n",
    "                idf = df.shape[0] / (ret[col].sum() + 1)\n",
    "                idf = np.log(idf)\n",
    "                self.idf[col] = idf\n",
    "\n",
    "            ret[col] = 1 + np.log((ret[col] + epsilon) / (cnts + epsilon))\n",
    "            ret[col] *= idf\n",
    "\n",
    "        # cnts = ret.sum(axis=1)\n",
    "        # for col in cols:\n",
    "        #     ret[col] = ret[col] / cnts\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def get_input_words(self, df):\n",
    "        tmp_df = df[(~df['text_change'].str.contains('=>')) & (\n",
    "            df['text_change'] != 'NoChange')].reset_index(drop=True)\n",
    "        tmp_df = tmp_df.groupby('id').agg({'text_change': list}).reset_index()\n",
    "        tmp_df['text_change'] = tmp_df['text_change'].apply(\n",
    "            lambda x: ''.join(x))\n",
    "        tmp_df['text_change'] = tmp_df['text_change'].apply(\n",
    "            lambda x: re.findall(r'q+', x))\n",
    "        tmp_df['input_word_count'] = tmp_df['text_change'].apply(len)\n",
    "        tmp_df['input_word_length_mean'] = tmp_df['text_change'].apply(\n",
    "            lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['input_word_length_max'] = tmp_df['text_change'].apply(\n",
    "            lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['input_word_length_std'] = tmp_df['text_change'].apply(\n",
    "            lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['input_word_length_median'] = tmp_df['text_change'].apply(\n",
    "            lambda x: np.median([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df.drop(['text_change'], axis=1, inplace=True)\n",
    "        return tmp_df\n",
    "\n",
    "    # 这里是我完全新加的特征，考察的是text_change中含有=>的情况，左侧会出现很多q，右边通常只有一个q，因此我就没有对右边进行考察\n",
    "    def get_change_words(self, df):\n",
    "        tmp_df = df[df['text_change'].str.contains(\n",
    "            '=>')].reset_index(drop=True)\n",
    "        tmp_df = tmp_df.groupby('id').agg({'text_change': list}).reset_index()\n",
    "        tmp_df['text_change'] = tmp_df['text_change'].apply(\n",
    "            lambda x: ''.join(x))\n",
    "        tmp_df['left_word'] = tmp_df['text_change'].apply(\n",
    "            lambda x: x.split('=>')[0])\n",
    "        tmp_df['left_word'] = tmp_df['left_word'].apply(\n",
    "            lambda x: re.findall(r'q+', x))\n",
    "        tmp_df['origin_word_count'] = tmp_df['left_word'].apply(len)\n",
    "        tmp_df['origin_word_length_mean'] = tmp_df['left_word'].apply(\n",
    "            lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['origin_word_length_max'] = tmp_df['left_word'].apply(\n",
    "            lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['origin_word_length_std'] = tmp_df['left_word'].apply(\n",
    "            lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['origin_word_length_median'] = tmp_df['left_word'].apply(\n",
    "            lambda x: np.median([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df = tmp_df.fillna(0.0)\n",
    "        tmp_df.drop(['text_change', 'left_word'], axis=1, inplace=True)\n",
    "        return tmp_df\n",
    "\n",
    "    def action_time_events_activities_all(self, df):\n",
    "        def action_time_events_activities(group):\n",
    "            features = {}\n",
    "\n",
    "            for event in self.events2:\n",
    "                event_group = group[group['up_event'] == event]\n",
    "                features[f'up_{event}_id_mean'] = event_group['action_time'].mean()\n",
    "                features[f'up_{event}_id_median'] = event_group['action_time'].median(\n",
    "                )\n",
    "                features[f'up_{event}_id_25%'] = event_group['action_time'].quantile(\n",
    "                    0.25)\n",
    "                features[f'up_{event}_id_75%'] = event_group['action_time'].quantile(\n",
    "                    0.75)\n",
    "                features[f'up_{event}_id_sum'] = event_group['action_time'].sum()\n",
    "\n",
    "            for activity in self.activities:\n",
    "                activity_group = group[group['activity'] == activity]\n",
    "                features[f'{activity}_id_mean'] = activity_group['action_time'].mean()\n",
    "                features[f'{activity}_id_median'] = activity_group['action_time'].median()\n",
    "                features[f'{activity}_id_25%'] = activity_group['action_time'].quantile(\n",
    "                    0.25)\n",
    "                features[f'{activity}_id_75%'] = activity_group['action_time'].quantile(\n",
    "                    0.75)\n",
    "                features[f'{activity}_id_sum'] = activity_group['action_time'].sum()\n",
    "\n",
    "            return pd.Series(features)\n",
    "\n",
    "        return df.groupby('id').apply(action_time_events_activities)\n",
    "\n",
    "    def make_feats(self, df):\n",
    "        feats = pd.DataFrame({'id': df['id'].unique().tolist()})\n",
    "\n",
    "        print(\"Engineering time data\")\n",
    "        for gap in self.gaps:\n",
    "            df[f'up_time_shift{gap}'] = df.groupby('id')['up_time'].shift(gap)\n",
    "            df[f'action_time_gap{gap}'] = df['down_time'] - \\\n",
    "                df[f'up_time_shift{gap}']\n",
    "        df.drop(\n",
    "            columns=[f'up_time_shift{gap}' for gap in self.gaps], inplace=True)\n",
    "\n",
    "        print(\"Engineering cursor position data\")\n",
    "        for gap in self.gaps:\n",
    "            df[f'cursor_position_shift{gap}'] = df.groupby(\n",
    "                'id')['cursor_position'].shift(gap)\n",
    "            df[f'cursor_position_change{gap}'] = df['cursor_position'] - \\\n",
    "                df[f'cursor_position_shift{gap}']\n",
    "        df.drop(\n",
    "            columns=[f'cursor_position_shift{gap}' for gap in self.gaps], inplace=True)\n",
    "\n",
    "        print(\"Engineering word count data\")\n",
    "        for gap in self.gaps:\n",
    "            df[f'word_count_shift{gap}'] = df.groupby(\n",
    "                'id')['word_count'].shift(gap)\n",
    "            df[f'word_count_change{gap}'] = df['word_count'] - \\\n",
    "                df[f'word_count_shift{gap}']\n",
    "        df.drop(\n",
    "            columns=[f'word_count_shift{gap}' for gap in self.gaps], inplace=True)\n",
    "\n",
    "        print(\"Engineering statistical summaries for features\")\n",
    "\n",
    "        feats_stat = [\n",
    "            ('activity', ['nunique']),\n",
    "            ('down_event', ['nunique']),\n",
    "            ('up_event', ['nunique']),\n",
    "            ('text_change', ['nunique'])\n",
    "        ]\n",
    "\n",
    "        for gap in self.gaps:\n",
    "            if gap == 1:\n",
    "                feats_stat.extend([\n",
    "                    (f'action_time_gap{gap}', [\n",
    "                        'sum', 'mean', 'std', 'median', 'skew']),\n",
    "                    (f'cursor_position_change{gap}', [\n",
    "                        'sum', 'max', 'min', 'mean', 'std', 'skew'])\n",
    "                ])\n",
    "            else:\n",
    "                feats_stat.extend([\n",
    "                    (f'action_time_gap{gap}', [\n",
    "                        'mean', 'std', 'median', 'skew']),\n",
    "                    (f'cursor_position_change{gap}', [\n",
    "                        'max', 'min', 'mean', 'std', 'skew'])\n",
    "                ])\n",
    "\n",
    "        pbar = tqdm(feats_stat)\n",
    "        for item in pbar:\n",
    "            colname, methods = item[0], item[1]\n",
    "            for method in methods:\n",
    "                pbar.set_postfix()\n",
    "                if isinstance(method, str):\n",
    "                    method_name = method\n",
    "                else:\n",
    "                    method_name = method.__name__\n",
    "                pbar.set_postfix(column=colname, method=method_name)\n",
    "                tmp_df = df.groupby(['id']).agg({colname: method}).reset_index().rename(\n",
    "                    columns={colname: f'{colname}_{method_name}'})\n",
    "                feats = feats.merge(tmp_df, on='id', how='left')\n",
    "\n",
    "        print(\"Engineering activity counts data\")\n",
    "        tmp_df = self.activity_counts(df)\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "        print(\"Engineering event counts data\")\n",
    "        tmp_df = self.event_counts(df, 'down_event')\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "        tmp_df = self.event_counts(df, 'up_event')\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "        print(\"Engineering text change counts data\")\n",
    "        tmp_df = self.text_change_counts(df)\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "        print(\"Engineering punctuation counts data\")\n",
    "        tmp_df = self.match_punctuations(df)\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "        print(\"Engineering input words data\")\n",
    "        tmp_df = self.get_input_words(df)\n",
    "        feats = pd.merge(feats, tmp_df, on='id', how='left')\n",
    "\n",
    "        # print(\"Engineering change words data\")\n",
    "        # tmp_df = self.get_change_words(df)\n",
    "        # feats = pd.merge(feats, tmp_df, on='id', how='left')\n",
    "\n",
    "        # print(\"Engineering action time features\")\n",
    "        # tmp_df = self.action_time_events_activities_all(df)\n",
    "        # tmp_df = tmp_df.reset_index()\n",
    "        # feats = pd.merge(feats, tmp_df, on='id', how='left')\n",
    "\n",
    "        print(\"Engineering ratios data\")\n",
    "\n",
    "        # feats.drop(columns=['up_time_max', 'event_id_max'], inplace=True)\n",
    "\n",
    "        return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f07bae6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T05:56:44.651131Z",
     "iopub.status.busy": "2024-01-09T05:56:44.650859Z",
     "iopub.status.idle": "2024-01-09T06:00:29.701088Z",
     "shell.execute_reply": "2024-01-09T06:00:29.700168Z"
    },
    "papermill": {
     "duration": 225.085587,
     "end_time": "2024-01-09T06:00:29.729143",
     "exception": false,
     "start_time": "2024-01-09T05:56:44.643556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Count by values features >\n",
      "< Input words stats features >\n",
      "< Numerical columns features >\n",
      "< Categorical columns features >\n",
      "< Idle time features >\n",
      "< P-bursts features >\n",
      "< R-bursts features >\n",
      "< Main Processor >\n",
      "Engineering time data\n",
      "Engineering cursor position data\n",
      "Engineering word count data\n",
      "Engineering statistical summaries for features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:40<00:00,  3.40s/it, column=cursor_position_change100, method=skew]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering activity counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 6046.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering event counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 4923.33it/s]\n",
      "100%|██████████| 2471/2471 [00:00<00:00, 5190.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering text change counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 5826.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering punctuation counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 5163.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering input words data\n",
      "Engineering ratios data\n",
      "< Essay Reconstruction >\n",
      "< Mapping >\n",
      "Number of features: 277\n",
      "< Testing Data >\n",
      "< Count by values features >\n",
      "< Input words stats features >\n",
      "< Numerical columns features >\n",
      "< Categorical columns features >\n",
      "< Idle time features >\n",
      "< P-bursts features >\n",
      "< R-bursts features >\n",
      "Engineering time data\n",
      "Engineering cursor position data\n",
      "Engineering word count data\n",
      "Engineering statistical summaries for features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 47.37it/s, column=cursor_position_change100, method=skew]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering activity counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 22671.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering event counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23045.63it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 36261.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering text change counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 18724.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering punctuation counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 24624.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering input words data\n",
      "Engineering ratios data\n",
      "< Learning and Evaluation >\n",
      "Epoch: 1 Fold: 1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51451\n",
      "[LightGBM] [Info] Number of data points in the train set: 2223, number of used features: 265\n",
      "[LightGBM] [Info] Start training from score 3.706928\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's rmse: 0.554234\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51475\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 265\n",
      "[LightGBM] [Info] Start training from score 3.713579\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's rmse: 0.521063\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51420\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 265\n",
      "[LightGBM] [Info] Start training from score 3.715378\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's rmse: 0.676858\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 4\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51429\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 265\n",
      "[LightGBM] [Info] Start training from score 3.709982\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's rmse: 0.614173\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 5\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51460\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 265\n",
      "[LightGBM] [Info] Start training from score 3.705036\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's rmse: 0.59579\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 6\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51430\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 265\n",
      "[LightGBM] [Info] Start training from score 3.707284\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[325]\tvalid_0's rmse: 0.593437\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 7\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51460\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 265\n",
      "[LightGBM] [Info] Start training from score 3.717176\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's rmse: 0.64805\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51464\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 265\n",
      "[LightGBM] [Info] Start training from score 3.702788\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's rmse: 0.636964\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 9\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51443\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 265\n",
      "[LightGBM] [Info] Start training from score 3.724371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[342]\tvalid_0's rmse: 0.626208\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 10\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51449\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 265\n",
      "[LightGBM] [Info] Start training from score 3.709982\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's rmse: 0.570145\n",
      "Evaluated only: rmse\n",
      "Avg Loss: 0.6052945632244783\n",
      "metric LGBM = 0.60529\n",
      "Epoch: 1 Fold: 1\n",
      "Epoch: 1 Fold: 2\n",
      "Epoch: 1 Fold: 3\n",
      "Epoch: 1 Fold: 4\n",
      "Epoch: 1 Fold: 5\n",
      "Epoch: 1 Fold: 6\n",
      "Epoch: 1 Fold: 7\n",
      "Epoch: 1 Fold: 8\n",
      "Epoch: 1 Fold: 9\n",
      "Epoch: 1 Fold: 10\n",
      "Avg Loss: 0.606001298138515\n",
      "metric XGB = 0.60600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>2.203923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2222bbbb</td>\n",
       "      <td>1.677323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4444cccc</td>\n",
       "      <td>1.732850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     score\n",
       "0  0000aaaa  2.203923\n",
       "1  2222bbbb  1.677323\n",
       "2  4444cccc  1.732850"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CFG:\n",
    "    is_train_lgbm_model = True\n",
    "    is_train_lgbm_optuna = False\n",
    "    is_train_xgb_model = True\n",
    "    is_train_xgb_optuna = False\n",
    "    is_train_cb_model = False\n",
    "    is_train_cb_optuna = False\n",
    "\n",
    "\n",
    "def q1(x):\n",
    "    return x.quantile(0.25)\n",
    "\n",
    "\n",
    "def q3(x):\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "\n",
    "AGGREGATIONS = ['count', 'mean', 'min', 'max',\n",
    "                'first', 'last', q1, 'median', q3, 'sum']\n",
    "\n",
    "WORD_AGGREGATIONS = ['count', 'mean', 'max', q1, 'median', q3, 'sum']\n",
    "\n",
    "num_cols = ['down_time', 'up_time', 'action_time',\n",
    "            'cursor_position', 'word_count']\n",
    "\n",
    "activities = ['Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste']\n",
    "\n",
    "events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft',\n",
    "          '.', ',', 'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']\n",
    "\n",
    "text_changes = ['q', ' ', '.', ',', '\\n', \"'\",\n",
    "                '\"', '-', '?', ';', '=', '/', '\\\\', ':']\n",
    "\n",
    "\n",
    "def count_by_values(df, colname, values):\n",
    "    fts = df.select(pl.col('id').unique(maintain_order=True))\n",
    "    for i, value in enumerate(values):\n",
    "        tmp_df = df.group_by('id').agg(pl.col(colname).is_in(\n",
    "            [value]).sum().alias(f'{colname}_{i}_cnt'))\n",
    "        fts = fts.join(tmp_df, on='id', how='left')\n",
    "    return fts\n",
    "\n",
    "\n",
    "def dev_feats(df):\n",
    "\n",
    "    print(\"< Count by values features >\")\n",
    "\n",
    "    feats = count_by_values(df, 'activity', activities)\n",
    "    feats = feats.join(count_by_values(df, 'text_change',\n",
    "                       text_changes), on='id', how='left')\n",
    "    feats = feats.join(count_by_values(\n",
    "        df, 'down_event', events), on='id', how='left')\n",
    "    feats = feats.join(count_by_values(\n",
    "        df, 'up_event', events), on='id', how='left')\n",
    "\n",
    "    print(\"< Input words stats features >\")\n",
    "\n",
    "    temp = df.filter((~pl.col('text_change').str.contains('=>'))\n",
    "                     & (pl.col('text_change') != 'NoChange'))\n",
    "    temp = temp.group_by('id').agg(\n",
    "        pl.col('text_change').str.concat('').str.extract_all(r'q+'))\n",
    "    temp = temp.with_columns(\n",
    "        input_word_count=pl.col('text_change').list.lengths(),\n",
    "        input_word_length_mean=pl.col('text_change').apply(\n",
    "            lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0)\n",
    "        ),\n",
    "        input_word_length_max=pl.col('text_change').apply(\n",
    "            lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0)\n",
    "        ),\n",
    "        input_word_length_std=pl.col('text_change').apply(\n",
    "            lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0)\n",
    "        ),\n",
    "        input_word_length_median=pl.col('text_change').apply(\n",
    "            lambda x: np.median([len(i) for i in x] if len(x) > 0 else 0)\n",
    "        ),\n",
    "        input_word_length_skew=pl.col('text_change').apply(\n",
    "            lambda x: skew([len(i) for i in x] if len(x) > 0 else 0)\n",
    "        )\n",
    "    )\n",
    "    temp = temp.drop('text_change')\n",
    "    feats = feats.join(temp, on='id', how='left')\n",
    "\n",
    "    print(\"< Numerical columns features >\")\n",
    "\n",
    "    temp = df.group_by(\"id\").agg(\n",
    "        pl.sum('action_time').suffix('_sum'),\n",
    "        pl.mean(num_cols).suffix('_mean'),\n",
    "        pl.std(num_cols).suffix('_std'),\n",
    "        pl.median(num_cols).suffix('_median'),\n",
    "        pl.min(num_cols).suffix('_min'),\n",
    "        pl.max(num_cols).suffix('_max'),\n",
    "        pl.quantile(num_cols, 0.25).suffix('_quantile25'),\n",
    "        pl.quantile(num_cols, 0.75).suffix('_quantile75')\n",
    "    )\n",
    "    feats = feats.join(temp, on='id', how='left')\n",
    "\n",
    "    print(\"< Categorical columns features >\")\n",
    "\n",
    "    temp = df.group_by(\"id\").agg(\n",
    "        pl.n_unique(['activity', 'down_event', 'up_event', 'text_change'])\n",
    "    )\n",
    "    feats = feats.join(temp, on='id', how='left')\n",
    "\n",
    "    print(\"< Idle time features >\")\n",
    "\n",
    "    temp = df.with_columns(pl.col('up_time').shift().over(\n",
    "        'id').alias('up_time_lagged'))\n",
    "    temp = temp.with_columns((abs(pl.col(\n",
    "        'down_time') - pl.col('up_time_lagged')) / 1000).fill_null(0).alias('time_diff'))\n",
    "    temp = temp.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "    temp = temp.group_by(\"id\").agg(\n",
    "        inter_key_largest_lantency=pl.max('time_diff'),\n",
    "        inter_key_median_lantency=pl.median('time_diff'),\n",
    "        mean_pause_time=pl.mean('time_diff'),\n",
    "        std_pause_time=pl.std('time_diff'),\n",
    "        total_pause_time=pl.sum('time_diff'),\n",
    "        pauses_zero_sec=pl.col('time_diff').filter(  # 新增特征\n",
    "            pl.col('time_diff') < 0.5\n",
    "        ).count(),\n",
    "        pauses_half_sec=pl.col('time_diff').filter(\n",
    "            (pl.col('time_diff') > 0.5) & (pl.col('time_diff') < 1)\n",
    "        ).count(),\n",
    "        pauses_1_sec=pl.col('time_diff').filter(\n",
    "            (pl.col('time_diff') > 1) & (pl.col('time_diff') < 1.5)\n",
    "        ).count(),\n",
    "        pauses_1_half_sec=pl.col('time_diff').filter(\n",
    "            (pl.col('time_diff') > 1.5) & (pl.col('time_diff') < 2)\n",
    "        ).count(),\n",
    "        pauses_2_sec=pl.col('time_diff').filter(\n",
    "            (pl.col('time_diff') > 2) & (pl.col('time_diff') < 3)\n",
    "        ).count(),\n",
    "        pauses_3_sec=pl.col('time_diff').filter(\n",
    "            pl.col('time_diff') > 3\n",
    "        ).count()\n",
    "    )\n",
    "    feats = feats.join(temp, on='id', how='left')\n",
    "\n",
    "    print(\"< P-bursts features >\")\n",
    "\n",
    "    temp = df.with_columns(pl.col('up_time').shift().over(\n",
    "        'id').alias('up_time_lagged'))\n",
    "    temp = temp.with_columns((abs(pl.col(\n",
    "        'down_time') - pl.col('up_time_lagged')) / 1000).fill_null(0).alias('time_diff'))\n",
    "    temp = temp.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "    temp = temp.with_columns(pl.col('time_diff') < 2)\n",
    "    temp = temp.with_columns(pl.when(pl.col(\"time_diff\") & pl.col(\"time_diff\").is_last(\n",
    "    )).then(pl.count()).over(pl.col(\"time_diff\").rle_id()).alias('P-bursts'))\n",
    "    temp = temp.drop_nulls()\n",
    "    temp = temp.group_by(\"id\").agg(\n",
    "        pl.mean('P-bursts').suffix('_mean'),\n",
    "        pl.std('P-bursts').suffix('_std'),\n",
    "        pl.count('P-bursts').suffix('_count'),\n",
    "        pl.median('P-bursts').suffix('_median'),\n",
    "        pl.max('P-bursts').suffix('_max'),\n",
    "        pl.first('P-bursts').suffix('_first'),\n",
    "        pl.last('P-bursts').suffix('_last')\n",
    "    )\n",
    "    feats = feats.join(temp, on='id', how='left')\n",
    "\n",
    "    print(\"< R-bursts features >\")\n",
    "\n",
    "    temp = df.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "    temp = temp.with_columns(pl.col('activity').is_in(['Remove/Cut']))\n",
    "    temp = temp.with_columns(pl.when(pl.col(\"activity\") & pl.col(\"activity\").is_last(\n",
    "    )).then(pl.count()).over(pl.col(\"activity\").rle_id()).alias('R-bursts'))\n",
    "    temp = temp.drop_nulls()\n",
    "    temp = temp.group_by(\"id\").agg(\n",
    "        pl.mean('R-bursts').suffix('_mean'),\n",
    "        pl.std('R-bursts').suffix('_std'),\n",
    "        pl.median('R-bursts').suffix('_median'),\n",
    "        pl.max('R-bursts').suffix('_max'),\n",
    "        pl.first('R-bursts').suffix('_first'),\n",
    "        pl.last('R-bursts').suffix('_last')\n",
    "    )\n",
    "    feats = feats.join(temp, on='id', how='left')\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "def reconstruct_essay(currTextInput):\n",
    "    essayText = \"\"\n",
    "    for Input in currTextInput.values:\n",
    "        if Input[0] == 'Replace':\n",
    "            replaceTxt = Input[2].split(' => ')\n",
    "            essayText = essayText[:Input[1] - len(replaceTxt[1])] + replaceTxt[1] + \\\n",
    "                essayText[Input[1] - len(replaceTxt[1]) + len(replaceTxt[0]):]\n",
    "            continue\n",
    "        if Input[0] == 'Paste':\n",
    "            essayText = essayText[:Input[1] - len(Input[2])] + \\\n",
    "                Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "            continue\n",
    "        if Input[0] == 'Remove/Cut':\n",
    "            essayText = essayText[:Input[1]] + \\\n",
    "                essayText[Input[1] + len(Input[2]):]\n",
    "            continue\n",
    "        if \"M\" in Input[0]:\n",
    "            croppedTxt = Input[0][10:]\n",
    "            splitTxt = croppedTxt.split(' To ')\n",
    "            valueArr = [item.split(', ') for item in splitTxt]\n",
    "            moveData = (int(valueArr[0][0][1:]), int(\n",
    "                valueArr[0][1][:-1]), int(valueArr[1][0][1:]), int(valueArr[1][1][:-1]))\n",
    "            if moveData[0] != moveData[2]:\n",
    "                if moveData[0] < moveData[2]:\n",
    "                    essayText = essayText[:moveData[0]] + \\\n",
    "                        essayText[moveData[1]:moveData[3]] + \\\n",
    "                        essayText[moveData[0]:moveData[1]] + \\\n",
    "                        essayText[moveData[3]:]\n",
    "                else:\n",
    "                    essayText = essayText[:moveData[2]] + \\\n",
    "                        essayText[moveData[0]:moveData[1]] + \\\n",
    "                        essayText[moveData[2]:moveData[0]] + \\\n",
    "                        essayText[moveData[1]:]\n",
    "            continue\n",
    "        essayText = essayText[:Input[1] - len(Input[2])] + \\\n",
    "            Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "    return essayText\n",
    "\n",
    "\n",
    "def get_essay_df(df):\n",
    "    df = df[df.activity != 'Nonproduction']\n",
    "    temp = df.groupby('id').apply(lambda x: reconstruct_essay(\n",
    "        x[['activity', 'cursor_position', 'text_change']]))\n",
    "    essay_df = pd.DataFrame({'id': df['id'].unique().tolist()})\n",
    "    essay_df = essay_df.merge(temp.rename('essay'), on='id')\n",
    "    return essay_df\n",
    "\n",
    "\n",
    "def word_feats(df):\n",
    "    df['word'] = df['essay'].apply(lambda x: re.split(' |\\\\n|\\\\.|\\\\?|\\\\!', x))\n",
    "    df = df.explode('word')\n",
    "    df['word_len'] = df['word'].apply(lambda x: len(x))\n",
    "    df = df[df['word_len'] != 0]\n",
    "\n",
    "    word_agg_df = df[['id', 'word_len']].groupby(['id']).agg(AGGREGATIONS)\n",
    "    word_agg_df.columns = ['_'.join(x) for x in word_agg_df.columns]\n",
    "    word_agg_df['id'] = word_agg_df.index\n",
    "    word_agg_df = word_agg_df.reset_index(drop=True)\n",
    "\n",
    "    # print(word_agg_df.shape)\n",
    "\n",
    "    for word_l in [5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "        word_agg_df[f'word_len_ge_{word_l}_count'] = \\\n",
    "            df[df['word_len'] == word_l].groupby(['id']).count().iloc[:, 0]\n",
    "        word_agg_df[f'word_len_ge_{word_l}_count'] = \\\n",
    "            word_agg_df[f'word_len_ge_{word_l}_count'].fillna(0)\n",
    "    word_agg_df = word_agg_df.reset_index(drop=True)\n",
    "\n",
    "    # print(word_agg_df.shape)\n",
    "\n",
    "    return word_agg_df\n",
    "\n",
    "\n",
    "def sent_feats(df):\n",
    "    df['sent'] = df['essay'].apply(lambda x: re.split('\\\\.|\\\\?|\\\\!', x))\n",
    "    df = df.explode('sent')\n",
    "    df['sent'] = df['sent'].apply(lambda x: x.replace('\\n', '').strip())\n",
    "    # Number of characters in sentences\n",
    "    df['sent_len'] = df['sent'].apply(lambda x: len(x))\n",
    "    # Number of words in sentences\n",
    "    df['sent_word_count'] = df['sent'].apply(lambda x: len(x.split(' ')))\n",
    "    df = df[df.sent_len != 0].reset_index(drop=True)\n",
    "\n",
    "    sent_agg_df = pd.concat([df[['id', 'sent_len']].groupby(['id']).agg(AGGREGATIONS),\n",
    "                             df[['id', 'sent_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1)\n",
    "    sent_agg_df.columns = ['_'.join(x) for x in sent_agg_df.columns]\n",
    "    sent_agg_df['id'] = sent_agg_df.index\n",
    "    sent_agg_df = sent_agg_df.reset_index(drop=True)\n",
    "    sent_agg_df.drop(columns=[\"sent_word_count_count\"], inplace=True)\n",
    "    sent_agg_df = sent_agg_df.rename(columns={\"sent_len_count\": \"sent_count\"})\n",
    "    return sent_agg_df\n",
    "\n",
    "\n",
    "def parag_feats(df):\n",
    "    df['paragraph'] = df['essay'].apply(lambda x: x.split('\\n'))\n",
    "    df = df.explode('paragraph')\n",
    "    # Number of characters in paragraphs\n",
    "    df['paragraph_len'] = df['paragraph'].apply(lambda x: len(x))\n",
    "    # Number of words in paragraphs\n",
    "    df['paragraph_word_count'] = df['paragraph'].apply(\n",
    "        lambda x: len(x.split(' ')))\n",
    "    df = df[df.paragraph_len != 0].reset_index(drop=True)\n",
    "\n",
    "    paragraph_agg_df = pd.concat([df[['id', 'paragraph_len']].groupby(['id']).agg(AGGREGATIONS),\n",
    "                                  df[['id', 'paragraph_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1)\n",
    "    paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n",
    "    paragraph_agg_df['id'] = paragraph_agg_df.index\n",
    "    paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n",
    "    paragraph_agg_df.drop(columns=[\"paragraph_word_count_count\"], inplace=True)\n",
    "    paragraph_agg_df = paragraph_agg_df.rename(\n",
    "        columns={\"paragraph_len_count\": \"paragraph_count\"})\n",
    "    return paragraph_agg_df\n",
    "\n",
    "\n",
    "def product_to_keys(logs, essays):\n",
    "    essays['product_len'] = essays.essay.str.len()\n",
    "    tmp_df = logs[logs.activity.isin(['Input', 'Remove/Cut'])].groupby(['id']).agg(\n",
    "        {'activity': 'count'}).reset_index().rename(columns={'activity': 'keys_pressed'})\n",
    "    essays = essays.merge(tmp_df, on='id', how='left')\n",
    "    essays['product_to_keys'] = essays['product_len'] / essays['keys_pressed']\n",
    "    return essays[['id', 'product_to_keys']]\n",
    "\n",
    "\n",
    "def get_keys_pressed_per_second(logs):\n",
    "    temp_df = logs[logs['activity'].isin(['Input', 'Remove/Cut'])].groupby(\n",
    "        ['id']).agg(keys_pressed=('event_id', 'count')).reset_index()\n",
    "    temp_df_2 = logs.groupby(['id']).agg(min_down_time=(\n",
    "        'down_time', 'min'), max_up_time=('up_time', 'max')).reset_index()\n",
    "    temp_df = temp_df.merge(temp_df_2, on='id', how='left')\n",
    "    temp_df['keys_per_second'] = temp_df['keys_pressed'] / \\\n",
    "        ((temp_df['max_up_time'] - temp_df['min_down_time']) / 1000)\n",
    "    return temp_df[['id', 'keys_per_second']]\n",
    "\n",
    "\n",
    "preprocessor = Preprocessor(seed=42)\n",
    "\n",
    "data_path = '/kaggle/input/linking-writing-processes-to-writing-quality/'\n",
    "train_logs = pl.scan_csv(data_path + 'train_logs.csv')\n",
    "train_feats = dev_feats(train_logs)\n",
    "train_feats = train_feats.collect().to_pandas()\n",
    "train_logs = train_logs.collect().to_pandas()\n",
    "\n",
    "print('< Main Processor >')\n",
    "train_feats = train_feats.merge(\n",
    "    preprocessor.make_feats(train_logs), on='id', how='left')\n",
    "\n",
    "print('< Essay Reconstruction >')\n",
    "train_essays = get_essay_df(train_logs)\n",
    "train_feats = train_feats.merge(word_feats(train_essays), on='id', how='left')\n",
    "train_feats = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n",
    "train_feats = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n",
    "train_feats = train_feats.merge(\n",
    "    get_keys_pressed_per_second(train_logs), on='id', how='left')\n",
    "train_feats = train_feats.merge(product_to_keys(\n",
    "    train_logs, train_essays), on='id', how='left')\n",
    "\n",
    "\n",
    "train_feats['word_time_ratio'] = train_feats['word_count_max'] / \\\n",
    "    train_feats['up_time_max']\n",
    "train_feats['position_time_ratio'] = train_feats['cursor_position_max'] / \\\n",
    "    train_feats['up_time_max']\n",
    "train_feats['word_per_action_time'] = train_feats['word_count_max'] / \\\n",
    "    train_feats['action_time_sum']\n",
    "train_feats['position_per_action_time'] = train_feats['cursor_position_max'] / \\\n",
    "    train_feats['action_time_sum']\n",
    "\n",
    "print('< Mapping >')\n",
    "train_scores = pd.read_csv(data_path + 'train_scores.csv')\n",
    "data = train_feats.merge(train_scores, on='id', how='left')\n",
    "data.to_csv(\"baseline_features.csv\", index=False)\n",
    "\n",
    "x = data.drop(['id', 'score'], axis=1)\n",
    "y = data['score'].values\n",
    "print(f'Number of features: {len(x.columns)}')\n",
    "\n",
    "\n",
    "print('< Testing Data >')\n",
    "test_logs = pl.scan_csv(data_path + 'test_logs.csv')\n",
    "test_feats = dev_feats(test_logs)\n",
    "test_feats = test_feats.collect().to_pandas()\n",
    "test_logs = test_logs.collect().to_pandas()\n",
    "\n",
    "test_essays = get_essay_df(test_logs)\n",
    "test_feats = test_feats.merge(\n",
    "    preprocessor.make_feats(test_logs), on='id', how='left')\n",
    "test_feats = test_feats.merge(word_feats(test_essays), on='id', how='left')\n",
    "test_feats = test_feats.merge(sent_feats(test_essays), on='id', how='left')\n",
    "test_feats = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n",
    "test_feats = test_feats.merge(\n",
    "    get_keys_pressed_per_second(test_logs), on='id', how='left')\n",
    "test_feats = test_feats.merge(product_to_keys(\n",
    "    test_logs, test_essays), on='id', how='left')\n",
    "\n",
    "test_feats['word_time_ratio'] = test_feats['word_count_max'] / \\\n",
    "    test_feats['up_time_max']\n",
    "test_feats['position_time_ratio'] = test_feats['cursor_position_max'] / \\\n",
    "    test_feats['up_time_max']\n",
    "test_feats['word_per_action_time'] = test_feats['word_count_max'] / \\\n",
    "    test_feats['action_time_sum']\n",
    "test_feats['position_per_action_time'] = test_feats['cursor_position_max'] / \\\n",
    "    test_feats['action_time_sum']\n",
    "\n",
    "test_ids = test_feats['id'].values\n",
    "testin_x = test_feats.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "def train_valid_split(data_x, data_y, train_idx, valid_idx):\n",
    "    x_train = data_x.iloc[train_idx]\n",
    "    y_train = data_y[train_idx]\n",
    "    x_valid = data_x.iloc[valid_idx]\n",
    "    y_valid = data_y[valid_idx]\n",
    "    return x_train, y_train, x_valid, y_valid\n",
    "\n",
    "\n",
    "def evaluate(data_x, data_y, model, random_state=42, n_splits=5, test_x=None):\n",
    "    skf = model_selection.StratifiedKFold(\n",
    "        n_splits=n_splits, random_state=random_state, shuffle=True\n",
    "    )\n",
    "    test_y = np.zeros(len(data_x)) if (\n",
    "        test_x is None) else np.zeros((len(test_x), n_splits))\n",
    "    for i, (train_index, valid_index) in enumerate(skf.split(data_x, data_y.astype(str))):\n",
    "        train_x, train_y, valid_x, valid_y = train_valid_split(\n",
    "            data_x, data_y, train_index, valid_index)\n",
    "        model.fit(train_x, train_y)\n",
    "        if test_x is None:\n",
    "            test_y[valid_index] = model.predict(valid_x)\n",
    "        else:\n",
    "            test_y[:, i] = model.predict(test_x)\n",
    "    return test_y if (test_x is None) else np.mean(test_y, axis=1)\n",
    "\n",
    "\n",
    "target_col = ['score']\n",
    "drop_cols = ['id']\n",
    "train_cols = [\n",
    "    col for col in train_feats.columns if col not in target_col + drop_cols\n",
    "]\n",
    "\n",
    "print('< Learning and Evaluation >')\n",
    "\n",
    "\n",
    "def train_lgbm_model(train_feats, test_feats):\n",
    "    TEST_PREDS = np.zeros((len(test_feats), 1))\n",
    "\n",
    "    os.makedirs('../baseline_lgb_models', exist_ok=True)\n",
    "\n",
    "    EPOCHS = 1\n",
    "    SPLIT = 10\n",
    "\n",
    "    test_prediction_list = []\n",
    "    model_dict = {}\n",
    "    scores = []\n",
    "    preds = np.zeros((len(train_feats), 1))\n",
    "\n",
    "    best_params = {\n",
    "        \"reg_alpha\": 0.6180352098860649,\n",
    "        \"reg_lambda\": 0.7866914194427166,\n",
    "        \"colsample_bytree\": 0.5584290371779084,\n",
    "        \"subsample\": 0.5805111806039674,\n",
    "        \"learning_rate\": 0.07951544203012983,\n",
    "        \"num_leaves\": 7,\n",
    "        \"max_depth\": 26,\n",
    "        \"min_child_samples\": 19,\n",
    "        \"n_estimators\": 9013,\n",
    "        'n_jobs': 4\n",
    "    }\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "        kf = model_selection.KFold(\n",
    "            n_splits=SPLIT, random_state=42 + i * 10, shuffle=True)\n",
    "        valid_preds = np.zeros(train_feats.shape[0])\n",
    "        X_test = test_feats[train_cols]\n",
    "\n",
    "        for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "            print(f'Epoch: {i + 1} Fold: {fold + 1}')\n",
    "            X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "            X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "            params = {\n",
    "                \"objective\": \"regression\",\n",
    "                \"metric\": \"rmse\",\n",
    "                \"random_state\": 42,\n",
    "                \"verbosity\": 1,\n",
    "                **best_params\n",
    "            }\n",
    "            model = lgb.LGBMRegressor(**params)\n",
    "            early_stopping_callback = lgb.early_stopping(\n",
    "                100, first_metric_only=True, verbose=True)\n",
    "\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_valid, y_valid)],\n",
    "                callbacks=[early_stopping_callback]\n",
    "            )\n",
    "\n",
    "            valid_predict = model.predict(X_valid)\n",
    "            valid_preds[valid_idx] = valid_predict\n",
    "            preds[valid_idx, 0] += valid_predict / EPOCHS\n",
    "\n",
    "            test_predict = model.predict(X_test)\n",
    "            TEST_PREDS[:, 0] += test_predict / EPOCHS / SPLIT\n",
    "            test_prediction_list.append(test_predict)\n",
    "\n",
    "            score = metrics.mean_squared_error(\n",
    "                y_valid, valid_predict, squared=False)\n",
    "            model_dict[f'Epoch{i + 1}-Fold{fold + 1}'] = model\n",
    "            model.booster_.save_model(\n",
    "                f'../baseline_lgb_models/lgbm_model_epoch{i + 1}_fold{fold + 1}.txt')\n",
    "\n",
    "        final_score = metrics.mean_squared_error(\n",
    "            train_feats[target_col], valid_preds, squared=False)\n",
    "        scores.append(final_score)\n",
    "\n",
    "    print(\"Avg Loss:\", np.mean(scores))\n",
    "\n",
    "    print('metric LGBM = {:.5f}'.format(metrics.mean_squared_error(\n",
    "        train_feats[target_col], preds[:, 0], squared=False)))\n",
    "\n",
    "    return TEST_PREDS\n",
    "\n",
    "\n",
    "def train_xgb_model(train_feats, test_feats):\n",
    "    TEST_PREDS = np.zeros((len(test_feats), 1))\n",
    "\n",
    "    os.makedirs('../baseline_xgb_models', exist_ok=True)\n",
    "\n",
    "    EPOCHS = 1\n",
    "    SPLIT = 10\n",
    "\n",
    "    test_prediction_list = []\n",
    "    model_dict = {}\n",
    "    scores = []\n",
    "    preds = np.zeros((len(train_feats), 1))\n",
    "\n",
    "    best_params = {\n",
    "        \"reg_alpha\": 0.4863505192262917,\n",
    "        \"reg_lambda\": 4.084406999178222,\n",
    "        \"colsample_bytree\": 0.6036892879612548,\n",
    "        \"subsample\": 0.5058861794630656,\n",
    "        \"learning_rate\": 0.01921463035110285,\n",
    "        \"max_depth\": 5,\n",
    "        \"min_child_weight\": 3.3827142252505014,\n",
    "        \"gamma\": 1.4356096570797314,\n",
    "        \"max_delta_step\": 4,\n",
    "        \"n_estimators\": 11995,\n",
    "        'n_jobs': 4\n",
    "    }\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "        kf = model_selection.KFold(\n",
    "            n_splits=SPLIT, random_state=42 + i * 10, shuffle=True)\n",
    "        valid_preds = np.zeros(train_feats.shape[0])\n",
    "        X_test = test_feats[train_cols]\n",
    "\n",
    "        for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "            print(f'Epoch: {i + 1} Fold: {fold + 1}')\n",
    "            X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "            X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "            params = {\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"eval_metric\": \"rmse\",\n",
    "                \"random_state\": 42,\n",
    "                \"verbosity\": 0,\n",
    "                **best_params\n",
    "            }\n",
    "            model = xgb.XGBRegressor(**params)\n",
    "\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_valid, y_valid)],\n",
    "                early_stopping_rounds=100,\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            valid_predict = model.predict(X_valid)\n",
    "            valid_preds[valid_idx] = valid_predict\n",
    "            preds[valid_idx, 0] += valid_predict / EPOCHS\n",
    "\n",
    "            test_predict = model.predict(X_test)\n",
    "            TEST_PREDS[:, 0] += test_predict / EPOCHS / SPLIT\n",
    "            test_prediction_list.append(test_predict)\n",
    "\n",
    "            score = metrics.mean_squared_error(\n",
    "                y_valid, valid_predict, squared=False)\n",
    "            model_dict[f'Epoch{i + 1}-Fold{fold + 1}'] = model\n",
    "            model.save_model(\n",
    "                f'../baseline_xgb_models/xgb_model_epoch{i + 1}_fold{fold + 1}.json')\n",
    "            # model.load_model(f'../baseline_xgb_models/xgb_model_epoch{i + 1}_fold{fold + 1}.json')\n",
    "\n",
    "        final_score = metrics.mean_squared_error(\n",
    "            train_feats[target_col], valid_preds, squared=False)\n",
    "        scores.append(final_score)\n",
    "\n",
    "    print(\"Avg Loss:\", np.mean(scores))\n",
    "\n",
    "    print('metric XGB = {:.5f}'.format(metrics.mean_squared_error(\n",
    "        train_feats[target_col], preds[:, 0], squared=False)))\n",
    "\n",
    "    return TEST_PREDS\n",
    "\n",
    "\n",
    "def train_cb_model(train_feats, test_feats):\n",
    "    TEST_PREDS = np.zeros((len(test_feats), 1))\n",
    "\n",
    "    os.makedirs('../baseline_cb_models', exist_ok=True)\n",
    "\n",
    "    EPOCHS = 1\n",
    "    SPLIT = 10\n",
    "\n",
    "    test_prediction_list = []\n",
    "    model_dict = {}\n",
    "    scores = []\n",
    "    preds = np.zeros((len(train_feats), 1))\n",
    "\n",
    "    best_params = {\n",
    "        'l2_leaf_reg': 3.8071290717767194,\n",
    "        'colsample_bylevel': 0.45216556596658897,\n",
    "        'subsample': 0.4832292138435902,\n",
    "        'learning_rate': 0.002,\n",
    "        'depth': 6,\n",
    "        'thread_count': 4,\n",
    "        'min_child_samples': 7,\n",
    "        'iterations': 11_861,\n",
    "    }\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "        kf = model_selection.KFold(\n",
    "            n_splits=SPLIT, random_state=42 + i * 10, shuffle=True)\n",
    "        valid_preds = np.zeros(train_feats.shape[0])\n",
    "        X_test = test_feats[train_cols]\n",
    "\n",
    "        for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "            print(f'Epoch: {i + 1} Fold: {fold + 1}')\n",
    "            X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "            X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "\n",
    "            model = cb.CatBoostRegressor(\n",
    "                loss_function='RMSE',\n",
    "                random_seed=2023,\n",
    "                verbose=True,\n",
    "                **best_params\n",
    "            )\n",
    "\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_valid, y_valid)],\n",
    "                early_stopping_rounds=100,\n",
    "                verbose=True\n",
    "            )\n",
    "\n",
    "            valid_predict = model.predict(X_valid)\n",
    "            valid_preds[valid_idx] = valid_predict\n",
    "            preds[valid_idx, 0] += valid_predict / EPOCHS\n",
    "\n",
    "            test_predict = model.predict(X_test)\n",
    "            TEST_PREDS[:, 0] += test_predict / EPOCHS / SPLIT\n",
    "            test_prediction_list.append(test_predict)\n",
    "\n",
    "            score = metrics.mean_squared_error(\n",
    "                y_valid, valid_predict, squared=False)\n",
    "            model_dict[f'Epoch{i + 1}-Fold{fold + 1}'] = model\n",
    "            model.save_model(\n",
    "                f'../baseline_cb_models/cb_model_epoch{i + 1}_fold{fold + 1}.cbm')\n",
    "            # model.load_model(f'../baseline_cb_models/cb_model_epoch{i + 1}_fold{fold + 1}.cbm')\n",
    "\n",
    "        final_score = metrics.mean_squared_error(\n",
    "            train_feats[target_col], valid_preds, squared=False)\n",
    "        scores.append(final_score)\n",
    "\n",
    "    print(\"Avg Loss:\", np.mean(scores))\n",
    "\n",
    "    print('metric CB = {:.5f}'.format(metrics.mean_squared_error(\n",
    "        train_feats[target_col], preds[:, 0], squared=False)))\n",
    "\n",
    "    return TEST_PREDS\n",
    "\n",
    "\n",
    "def train_lgbm_optuna(train_feats):\n",
    "    os.makedirs('../baseline_lgb_models_optuna', exist_ok=True)\n",
    "\n",
    "    def objective(trial):\n",
    "        EPOCHS = 1\n",
    "        SPLIT = 10\n",
    "\n",
    "        model_dict = {}\n",
    "        scores = []\n",
    "        preds = np.zeros((len(train_feats), 1))\n",
    "\n",
    "        best_params = {\n",
    "            'reg_alpha': trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "            'reg_lambda': trial.suggest_float(\"reg_lambda\", 0.0, 5.0),\n",
    "            'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "            'subsample': trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "            'learning_rate': trial.suggest_float(\"learning_rate\", 1e-4, 1e-1),\n",
    "            'num_leaves': trial.suggest_int(\"num_leaves\", 5, 50),\n",
    "            'max_depth': trial.suggest_int(\"max_depth\", 5, 30),\n",
    "            'min_child_samples': trial.suggest_int(\"min_child_samples\", 2, 30),\n",
    "            'n_jobs': 4,\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 1000, 20000)\n",
    "        }\n",
    "\n",
    "        for i in range(EPOCHS):\n",
    "            kf = model_selection.KFold(\n",
    "                n_splits=SPLIT, random_state=42 + i * 10, shuffle=True)\n",
    "            valid_preds = np.zeros(train_feats.shape[0])\n",
    "\n",
    "            for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "                print(f'Epoch: {i + 1} Fold: {fold + 1}')\n",
    "                X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "                X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "                params = {\n",
    "                    \"objective\": \"regression\",\n",
    "                    \"metric\": \"rmse\",\n",
    "                    \"random_state\": 42,\n",
    "                    \"verbosity\": -1,\n",
    "                    **best_params\n",
    "                }\n",
    "                model = lgb.LGBMRegressor(**params)\n",
    "                early_stopping_callback = lgb.early_stopping(\n",
    "                    100, first_metric_only=True, verbose=False\n",
    "                )\n",
    "\n",
    "                model.fit(\n",
    "                    X_train, y_train,\n",
    "                    eval_set=[(X_valid, y_valid)],\n",
    "                    callbacks=[early_stopping_callback]\n",
    "                )\n",
    "\n",
    "                valid_predict = model.predict(X_valid)\n",
    "                valid_preds[valid_idx] = valid_predict\n",
    "                preds[valid_idx, 0] += valid_predict / EPOCHS\n",
    "\n",
    "                score = metrics.mean_squared_error(\n",
    "                    y_valid, valid_predict, squared=False)\n",
    "                model_dict[f'Epoch{i + 1}-Fold{fold + 1}'] = model\n",
    "                model.booster_.save_model(\n",
    "                    f'../baseline_lgb_models_optuna/lgbm_model_epoch{i + 1}_fold{fold + 1}.txt')\n",
    "\n",
    "            final_score = metrics.mean_squared_error(\n",
    "                train_feats[target_col], valid_preds, squared=False)\n",
    "            scores.append(final_score)\n",
    "\n",
    "        print(\"Avg Loss:\", np.mean(scores))\n",
    "        return np.mean(scores)\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    print(\"LightGBM Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"Value: {trial.value}\")\n",
    "    print(\"Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    with open('lgbm_best_params.json', 'w') as json_file:\n",
    "        json.dump(trial.params, json_file, indent=4)\n",
    "\n",
    "    print(\"Save LightGBM best_params to json file\")\n",
    "\n",
    "\n",
    "def train_xgb_optuna(train_feats):\n",
    "    os.makedirs('../baseline_xgb_models_optuna', exist_ok=True)\n",
    "\n",
    "    def objective(trial):\n",
    "        EPOCHS = 1\n",
    "        SPLIT = 10\n",
    "\n",
    "        model_dict = {}\n",
    "        scores = []\n",
    "        preds = np.zeros((len(train_feats), 1))\n",
    "\n",
    "        best_params = {\n",
    "            'reg_alpha': trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "            'reg_lambda': trial.suggest_float(\"reg_lambda\", 0.0, 5.0),\n",
    "            'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "            'subsample': trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "            'learning_rate': trial.suggest_float(\"learning_rate\", 1e-4, 1e-1),\n",
    "            'max_depth': trial.suggest_int(\"max_depth\", 5, 30),\n",
    "            'min_child_weight': trial.suggest_float(\"min_child_weight\", 1.0, 5.0),\n",
    "            'gamma': trial.suggest_float(\"gamma\", 0.0, 10.0),\n",
    "            'max_delta_step': trial.suggest_int(\"max_delta_step\", 1, 5),\n",
    "            'n_jobs': 4,\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 1000, 20000)\n",
    "        }\n",
    "\n",
    "        for i in range(EPOCHS):\n",
    "            kf = model_selection.KFold(\n",
    "                n_splits=SPLIT, random_state=42 + i * 10, shuffle=True\n",
    "            )\n",
    "            valid_preds = np.zeros(train_feats.shape[0])\n",
    "\n",
    "            for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "                print(f'Epoch: {i + 1} Fold: {fold + 1}')\n",
    "                X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "                X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "                params = {\n",
    "                    \"objective\": \"reg:squarederror\",\n",
    "                    \"eval_metric\": \"rmse\",\n",
    "                    \"random_state\": 42,\n",
    "                    \"verbosity\": 0,\n",
    "                    **best_params\n",
    "                }\n",
    "                model = xgb.XGBRegressor(**params)\n",
    "\n",
    "                model.fit(\n",
    "                    X_train, y_train,\n",
    "                    eval_set=[(X_valid, y_valid)],\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose=False\n",
    "                )\n",
    "\n",
    "                valid_predict = model.predict(X_valid)\n",
    "                valid_preds[valid_idx] = valid_predict\n",
    "                preds[valid_idx, 0] += valid_predict / EPOCHS\n",
    "\n",
    "                score = metrics.mean_squared_error(\n",
    "                    y_valid, valid_predict, squared=False)\n",
    "                model_dict[f'Epoch{i + 1}-Fold{fold + 1}'] = model\n",
    "                model.save_model(\n",
    "                    f'../baseline_xgb_models_optuna/xgb_model_epoch{i + 1}_fold{fold + 1}.json')\n",
    "\n",
    "            final_score = metrics.mean_squared_error(\n",
    "                train_feats[target_col], valid_preds, squared=False)\n",
    "            scores.append(final_score)\n",
    "\n",
    "        print(\"Avg Loss:\", np.mean(scores))\n",
    "        return np.mean(scores)\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    print(\"XGBoost Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"Value: {trial.value}\")\n",
    "    print(\"Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    with open('xgb_best_params.json', 'w') as json_file:\n",
    "        json.dump(trial.params, json_file, indent=4)\n",
    "\n",
    "    print(\"Save XGBoost best_params to json file\")\n",
    "\n",
    "\n",
    "def train_cb_optuna(train_feats):\n",
    "    os.makedirs('../baseline_cb_models_optuna', exist_ok=True)\n",
    "\n",
    "    def objective(trial):\n",
    "        EPOCHS = 1\n",
    "        SPLIT = 10\n",
    "\n",
    "        model_dict = {}\n",
    "        scores = []\n",
    "        preds = np.zeros((len(train_feats), 1))\n",
    "\n",
    "        best_params = {\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 10.0),\n",
    "            'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 1.0),\n",
    "            'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True),\n",
    "            'depth': trial.suggest_int('depth', 1, 10),\n",
    "            'iterations': trial.suggest_int('iterations', 1000, 15000),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 1, 20),\n",
    "            'thread_count': 4\n",
    "        }\n",
    "\n",
    "        for i in range(EPOCHS):\n",
    "            kf = model_selection.KFold(\n",
    "                n_splits=SPLIT, random_state=42 + i * 10, shuffle=True)\n",
    "            valid_preds = np.zeros(train_feats.shape[0])\n",
    "\n",
    "            for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "                print(f'Epoch: {i + 1} Fold: {fold + 1}')\n",
    "                X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "                X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "\n",
    "                model = cb.CatBoostRegressor(\n",
    "                    loss_function='RMSE',\n",
    "                    random_seed=2023,\n",
    "                    verbose=False,\n",
    "                    **best_params\n",
    "                )\n",
    "\n",
    "                model.fit(\n",
    "                    X_train, y_train,\n",
    "                    eval_set=[(X_valid, y_valid)],\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose=True\n",
    "                )\n",
    "\n",
    "                valid_predict = model.predict(X_valid)\n",
    "                valid_preds[valid_idx] = valid_predict\n",
    "                preds[valid_idx, 0] += valid_predict / EPOCHS\n",
    "\n",
    "                score = metrics.mean_squared_error(\n",
    "                    y_valid, valid_predict, squared=False)\n",
    "                model_dict[f'Epoch{i + 1}-Fold{fold + 1}'] = model\n",
    "                model.save_model(\n",
    "                    f'../baseline_cb_models_optuna/cb_model_epoch{i + 1}_fold{fold + 1}.cbm')\n",
    "\n",
    "            final_score = metrics.mean_squared_error(\n",
    "                train_feats[target_col], valid_preds, squared=False)\n",
    "            scores.append(final_score)\n",
    "\n",
    "        print(\"Avg Loss:\", np.mean(scores))\n",
    "        return np.mean(scores)\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    print(\"CatBoost Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"Value: {trial.value}\")\n",
    "    print(\"Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    with open('cb_best_params.json', 'w') as json_file:\n",
    "        json.dump(trial.params, json_file, indent=4)\n",
    "\n",
    "    print(\"Save catboost best_params to json file\")\n",
    "\n",
    "\n",
    "if CFG.is_train_lgbm_optuna:\n",
    "    train_lgbm_optuna(train_feats=data)\n",
    "\n",
    "if CFG.is_train_xgb_optuna:\n",
    "    train_xgb_optuna(train_feats=data)\n",
    "\n",
    "if CFG.is_train_cb_optuna:\n",
    "    train_cb_optuna(train_feats=data)\n",
    "\n",
    "if CFG.is_train_lgbm_model:\n",
    "    lgbm_preds = train_lgbm_model(train_feats=data, test_feats=test_feats)\n",
    "\n",
    "if CFG.is_train_xgb_model:\n",
    "    xgb_preds = train_xgb_model(train_feats=data, test_feats=test_feats)\n",
    "\n",
    "if CFG.is_train_cb_model:\n",
    "    cb_preds = train_cb_model(train_feats=data, test_feats=test_feats)\n",
    "\n",
    "weights = [0.5, 0.5]\n",
    "\n",
    "test_preds = np.zeros(test_feats.shape[0])\n",
    "test_preds = lgbm_preds * weights[0] + xgb_preds * weights[1]\n",
    "\n",
    "test_feats['score'] = test_preds\n",
    "sub1 = test_feats[['id', 'score']]\n",
    "sub1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e577db60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T06:00:29.783516Z",
     "iopub.status.busy": "2024-01-09T06:00:29.782904Z",
     "iopub.status.idle": "2024-01-09T06:00:29.788665Z",
     "shell.execute_reply": "2024-01-09T06:00:29.787832Z"
    },
    "papermill": {
     "duration": 0.034821,
     "end_time": "2024-01-09T06:00:29.790505",
     "exception": false,
     "start_time": "2024-01-09T06:00:29.755684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "from sklearn import metrics, model_selection\n",
    "from collections import defaultdict, Counter\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import optuna\n",
    "from scipy.stats import skew, kurtosis\n",
    "import warnings\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "753f2d4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T06:00:29.845258Z",
     "iopub.status.busy": "2024-01-09T06:00:29.844962Z",
     "iopub.status.idle": "2024-01-09T06:00:29.903949Z",
     "shell.execute_reply": "2024-01-09T06:00:29.903248Z"
    },
    "papermill": {
     "duration": 0.088976,
     "end_time": "2024-01-09T06:00:29.905834",
     "exception": false,
     "start_time": "2024-01-09T06:00:29.816858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kurtosis_func(x): return x.kurt()\n",
    "\n",
    "\n",
    "def q1(x):\n",
    "    return x.quantile(0.25)\n",
    "\n",
    "\n",
    "def q3(x):\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, seed):\n",
    "        self.seed = seed\n",
    "\n",
    "        self.activities = ['Input', 'Remove/Cut',\n",
    "                           'Nonproduction', 'Replace', 'Paste']\n",
    "\n",
    "        self.events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft',\n",
    "                       'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', 'Delete', 'Unidentified']\n",
    "\n",
    "        self.events2 = ['q', 'Space', 'Backspace']\n",
    "\n",
    "        self.text_changes = ['q', ' ', 'NoChange', '.', ',', '\\n', \"'\",\n",
    "                             '\"', '-', '?', ';', '=', '/', '\\\\', ':']\n",
    "\n",
    "        # self.text_changes = ['q', ' ', 'NoChange', ',']\n",
    "\n",
    "        self.punctuations = ['\"', '.', ',', \"'\", '-', ';', ':', '?', '!', '<', '>', '/',\n",
    "                             '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+', '`', '~',\n",
    "                             '|', '!', '\\\\']\n",
    "\n",
    "        self.gaps = [1]\n",
    "\n",
    "        self.idf = defaultdict(float)\n",
    "\n",
    "        self.device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "\n",
    "    def activity_counts(self, df):\n",
    "        tmp_df = df.groupby('id').agg({'activity': list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tqdm(tmp_df['activity'].values):\n",
    "            items = list(Counter(li).items())\n",
    "            di = dict()\n",
    "            for k in self.activities:\n",
    "                di[k] = 0\n",
    "#             di[\"Move\"] = 0\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in di:\n",
    "                    di[k] = v\n",
    "#                 else:\n",
    "#                     di[\"Move\"] += v\n",
    "            ret.append(di)\n",
    "        ret = pd.DataFrame(ret)\n",
    "        cols = [f'activity_{i}_count' for i in range(len(ret.columns))]\n",
    "        ret.columns = cols\n",
    "\n",
    "        cnts = ret.sum(1)\n",
    "        epsilon = 1e-15\n",
    "\n",
    "        for col in cols:\n",
    "            if col in self.idf.keys():\n",
    "                idf = self.idf[col]\n",
    "            else:\n",
    "                idf = df.shape[0] / (ret[col].sum() + 1)\n",
    "                idf = np.log(idf)\n",
    "                self.idf[col] = idf\n",
    "\n",
    "            ret[col] = 1 + np.log((ret[col] + epsilon) / (cnts + epsilon))\n",
    "            ret[col] *= idf\n",
    "\n",
    "        # cnts = ret.sum(axis=1)\n",
    "        # for col in cols:\n",
    "        #     ret[col] = ret[col] / cnts\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def match_punctuations(self, df):\n",
    "        tmp_df = df.groupby('id').agg({'down_event': list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tqdm(tmp_df['down_event'].values):\n",
    "            cnt = 0\n",
    "            items = list(Counter(li).items())\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in self.punctuations:\n",
    "                    cnt += v\n",
    "            ret.append(cnt)\n",
    "        ret = pd.DataFrame({'punct_cnt': ret})\n",
    "        return ret\n",
    "\n",
    "    def text_change_counts(self, df):\n",
    "        tmp_df = df.groupby('id').agg({'text_change': list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tqdm(tmp_df['text_change'].values):\n",
    "            items = list(Counter(li).items())\n",
    "            di = dict()\n",
    "            for k in self.text_changes:\n",
    "                di[k] = 0\n",
    "#             di['Change'] = 0\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in di:\n",
    "                    di[k] = v\n",
    "                elif k.find('q') != -1 and not k.find('=>') != -1:\n",
    "                    di['q'] += v\n",
    "#                 elif k.find('=>') != -1:\n",
    "#                     di['Change'] += v\n",
    "            ret.append(di)\n",
    "        ret = pd.DataFrame(ret)\n",
    "        cols = [f'text_change_{i}_count' for i in range(len(ret.columns))]\n",
    "        ret.columns = cols\n",
    "\n",
    "        cnts = ret.sum(1)\n",
    "        epsilon = 1e-15\n",
    "\n",
    "        for col in cols:\n",
    "            if col in self.idf.keys():\n",
    "                idf = self.idf[col]\n",
    "            else:\n",
    "                idf = df.shape[0] / (ret[col].sum() + 1)\n",
    "                idf = np.log(idf)\n",
    "                self.idf[col] = idf\n",
    "\n",
    "            ret[col] = 1 + np.log((ret[col] + epsilon) / (cnts + epsilon))\n",
    "            ret[col] *= idf\n",
    "\n",
    "        # cnts = ret.sum(axis=1)\n",
    "        # for col in cols:\n",
    "        #     ret[col] = ret[col] / cnts\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def event_counts(self, df, colname):\n",
    "        tmp_df = df.groupby('id').agg({colname: list}).reset_index()\n",
    "        ret = list()\n",
    "        for li in tqdm(tmp_df[colname].values):\n",
    "            items = list(Counter(li).items())\n",
    "            di = dict()\n",
    "            for k in self.events:\n",
    "                di[k] = 0\n",
    "#             di['Other'] = 0\n",
    "            for item in items:\n",
    "                k, v = item[0], item[1]\n",
    "                if k in di:\n",
    "                    di[k] = v\n",
    "#                 else:\n",
    "#                     di['Other'] += v\n",
    "            ret.append(di)\n",
    "        ret = pd.DataFrame(ret)\n",
    "        cols = [f'{colname}_{i}_count' for i in range(len(ret.columns))]\n",
    "        ret.columns = cols\n",
    "\n",
    "        cnts = ret.sum(1)\n",
    "        epsilon = 1e-15\n",
    "\n",
    "        for col in cols:\n",
    "            if col in self.idf.keys():\n",
    "                idf = self.idf[col]\n",
    "            else:\n",
    "                idf = df.shape[0] / (ret[col].sum() + 1)\n",
    "                idf = np.log(idf)\n",
    "                self.idf[col] = idf\n",
    "\n",
    "            ret[col] = 1 + np.log((ret[col] + epsilon) / (cnts + epsilon))\n",
    "            ret[col] *= idf\n",
    "\n",
    "        # cnts = ret.sum(axis=1)\n",
    "        # for col in cols:\n",
    "        #     ret[col] = ret[col] / cnts\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def get_input_words(self, df):\n",
    "        tmp_df = df[(~df['text_change'].str.contains('=>')) & (\n",
    "            df['text_change'] != 'NoChange')].reset_index(drop=True)\n",
    "        tmp_df = tmp_df.groupby('id').agg({'text_change': list}).reset_index()\n",
    "        tmp_df['text_change'] = tmp_df['text_change'].apply(\n",
    "            lambda x: ''.join(x))\n",
    "        tmp_df['text_change'] = tmp_df['text_change'].apply(\n",
    "            lambda x: re.findall(r'q+', x))\n",
    "        tmp_df['input_word_count'] = tmp_df['text_change'].apply(len)\n",
    "        tmp_df['input_word_length_mean'] = tmp_df['text_change'].apply(\n",
    "            lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['input_word_length_max'] = tmp_df['text_change'].apply(\n",
    "            lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['input_word_length_std'] = tmp_df['text_change'].apply(\n",
    "            lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['input_word_length_median'] = tmp_df['text_change'].apply(\n",
    "            lambda x: np.median([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df.drop(['text_change'], axis=1, inplace=True)\n",
    "        return tmp_df\n",
    "\n",
    "    # 这里是我完全新加的特征，考察的是text_change中含有=>的情况，左侧会出现很多q，右边通常只有一个q，因此我就没有对右边进行考察\n",
    "    def get_change_words(self, df):\n",
    "        tmp_df = df[df['text_change'].str.contains(\n",
    "            '=>')].reset_index(drop=True)\n",
    "        tmp_df = tmp_df.groupby('id').agg({'text_change': list}).reset_index()\n",
    "        tmp_df['text_change'] = tmp_df['text_change'].apply(\n",
    "            lambda x: ''.join(x))\n",
    "        tmp_df['left_word'] = tmp_df['text_change'].apply(\n",
    "            lambda x: x.split('=>')[0])\n",
    "        tmp_df['left_word'] = tmp_df['left_word'].apply(\n",
    "            lambda x: re.findall(r'q+', x))\n",
    "        tmp_df['origin_word_count'] = tmp_df['left_word'].apply(len)\n",
    "        tmp_df['origin_word_length_mean'] = tmp_df['left_word'].apply(\n",
    "            lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['origin_word_length_max'] = tmp_df['left_word'].apply(\n",
    "            lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['origin_word_length_std'] = tmp_df['left_word'].apply(\n",
    "            lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df['origin_word_length_median'] = tmp_df['left_word'].apply(\n",
    "            lambda x: np.median([len(i) for i in x] if len(x) > 0 else 0))\n",
    "        tmp_df = tmp_df.fillna(0.0)\n",
    "        tmp_df.drop(['text_change', 'left_word'], axis=1, inplace=True)\n",
    "        return tmp_df\n",
    "\n",
    "    def action_time_events_activities_all(self, df):\n",
    "        def action_time_events_activities(group):\n",
    "            features = {}\n",
    "\n",
    "            for event in self.events2:\n",
    "                event_group = group[group['up_event'] == event]\n",
    "                features[f'up_{event}_id_mean'] = event_group['action_time'].mean()\n",
    "                features[f'up_{event}_id_median'] = event_group['action_time'].median(\n",
    "                )\n",
    "                features[f'up_{event}_id_25%'] = event_group['action_time'].quantile(\n",
    "                    0.25)\n",
    "                features[f'up_{event}_id_75%'] = event_group['action_time'].quantile(\n",
    "                    0.75)\n",
    "                features[f'up_{event}_id_sum'] = event_group['action_time'].sum()\n",
    "\n",
    "            for activity in self.activities:\n",
    "                activity_group = group[group['activity'] == activity]\n",
    "                features[f'{activity}_id_mean'] = activity_group['action_time'].mean()\n",
    "                features[f'{activity}_id_median'] = activity_group['action_time'].median()\n",
    "                features[f'{activity}_id_25%'] = activity_group['action_time'].quantile(\n",
    "                    0.25)\n",
    "                features[f'{activity}_id_75%'] = activity_group['action_time'].quantile(\n",
    "                    0.75)\n",
    "                features[f'{activity}_id_sum'] = activity_group['action_time'].sum()\n",
    "\n",
    "            return pd.Series(features)\n",
    "\n",
    "        return df.groupby('id').apply(action_time_events_activities)\n",
    "\n",
    "    def make_feats(self, df):\n",
    "        feats = pd.DataFrame({'id': df['id'].unique().tolist()})\n",
    "\n",
    "        print(\"Engineering time data\")\n",
    "        for gap in self.gaps:\n",
    "            df[f'up_time_shift{gap}'] = df.groupby('id')['up_time'].shift(gap)\n",
    "            df[f'action_time_gap{gap}'] = df['down_time'] - \\\n",
    "                df[f'up_time_shift{gap}']\n",
    "        df.drop(\n",
    "            columns=[f'up_time_shift{gap}' for gap in self.gaps], inplace=True)\n",
    "\n",
    "        print(\"Engineering cursor position data\")\n",
    "        for gap in self.gaps:\n",
    "            df[f'cursor_position_shift{gap}'] = df.groupby(\n",
    "                'id')['cursor_position'].shift(gap)\n",
    "            df[f'cursor_position_change{gap}'] = df['cursor_position'] - \\\n",
    "                df[f'cursor_position_shift{gap}']\n",
    "        df.drop(\n",
    "            columns=[f'cursor_position_shift{gap}' for gap in self.gaps], inplace=True)\n",
    "\n",
    "        print(\"Engineering word count data\")\n",
    "        for gap in self.gaps:\n",
    "            df[f'word_count_shift{gap}'] = df.groupby(\n",
    "                'id')['word_count'].shift(gap)\n",
    "            df[f'word_count_change{gap}'] = df['word_count'] - \\\n",
    "                df[f'word_count_shift{gap}']\n",
    "        df.drop(\n",
    "            columns=[f'word_count_shift{gap}' for gap in self.gaps], inplace=True)\n",
    "\n",
    "        print(\"Engineering statistical summaries for features\")\n",
    "\n",
    "        feats_stat = [\n",
    "            ('activity', ['nunique']),\n",
    "            ('down_event', ['nunique']),\n",
    "            ('up_event', ['nunique']),\n",
    "            ('text_change', ['nunique'])\n",
    "        ]\n",
    "\n",
    "        for gap in self.gaps:\n",
    "            if gap == 1:\n",
    "                feats_stat.extend([\n",
    "                    (f'action_time_gap{gap}', [\n",
    "                        'sum', 'mean', 'std', 'median', 'skew']),\n",
    "                    (f'cursor_position_change{gap}', [\n",
    "                        'sum', 'max', 'min', 'mean', 'std', 'skew'])\n",
    "                ])\n",
    "            else:\n",
    "                feats_stat.extend([\n",
    "                    (f'action_time_gap{gap}', [\n",
    "                        'mean', 'std', 'median', 'skew']),\n",
    "                    (f'cursor_position_change{gap}', [\n",
    "                        'max', 'min', 'mean', 'std', 'skew'])\n",
    "                ])\n",
    "\n",
    "        pbar = tqdm(feats_stat)\n",
    "        for item in pbar:\n",
    "            colname, methods = item[0], item[1]\n",
    "            for method in methods:\n",
    "                pbar.set_postfix()\n",
    "                if isinstance(method, str):\n",
    "                    method_name = method\n",
    "                else:\n",
    "                    method_name = method.__name__\n",
    "                pbar.set_postfix(column=colname, method=method_name)\n",
    "                tmp_df = df.groupby(['id']).agg({colname: method}).reset_index().rename(\n",
    "                    columns={colname: f'{colname}_{method_name}'})\n",
    "                feats = feats.merge(tmp_df, on='id', how='left')\n",
    "\n",
    "        print(\"Engineering activity counts data\")\n",
    "        tmp_df = self.activity_counts(df)\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "        print(\"Engineering event counts data\")\n",
    "        tmp_df = self.event_counts(df, 'down_event')\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "        tmp_df = self.event_counts(df, 'up_event')\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "        print(\"Engineering text change counts data\")\n",
    "        tmp_df = self.text_change_counts(df)\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "        print(\"Engineering punctuation counts data\")\n",
    "        tmp_df = self.match_punctuations(df)\n",
    "        feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "        print(\"Engineering input words data\")\n",
    "        tmp_df = self.get_input_words(df)\n",
    "        feats = pd.merge(feats, tmp_df, on='id', how='left')\n",
    "\n",
    "        # print(\"Engineering change words data\")\n",
    "        # tmp_df = self.get_change_words(df)\n",
    "        # feats = pd.merge(feats, tmp_df, on='id', how='left')\n",
    "\n",
    "        # print(\"Engineering action time features\")\n",
    "        # tmp_df = self.action_time_events_activities_all(df)\n",
    "        # tmp_df = tmp_df.reset_index()\n",
    "        # feats = pd.merge(feats, tmp_df, on='id', how='left')\n",
    "\n",
    "        print(\"Engineering ratios data\")\n",
    "\n",
    "        # feats.drop(columns=['up_time_max', 'event_id_max'], inplace=True)\n",
    "\n",
    "        return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48eac2a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T06:00:29.962037Z",
     "iopub.status.busy": "2024-01-09T06:00:29.961726Z",
     "iopub.status.idle": "2024-01-09T06:05:03.458666Z",
     "shell.execute_reply": "2024-01-09T06:05:03.457726Z"
    },
    "papermill": {
     "duration": 273.567336,
     "end_time": "2024-01-09T06:05:03.500371",
     "exception": false,
     "start_time": "2024-01-09T06:00:29.933035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Count by values features >\n",
      "< Input words stats features >\n",
      "< Numerical columns features >\n",
      "< Categorical columns features >\n",
      "< Idle time features >\n",
      "< P-bursts features >\n",
      "< R-bursts features >\n",
      "< Main Processor >\n",
      "Engineering time data\n",
      "Engineering cursor position data\n",
      "Engineering word count data\n",
      "Engineering statistical summaries for features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:17<00:00,  2.92s/it, column=cursor_position_change1, method=skew]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering activity counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 6162.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering event counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 5232.44it/s]\n",
      "100%|██████████| 2471/2471 [00:00<00:00, 5228.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering text change counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 5875.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering punctuation counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2471/2471 [00:00<00:00, 5109.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering input words data\n",
      "Engineering ratios data\n",
      "< Essay Reconstruction >\n",
      "< Mapping >\n",
      "Number of features: 252\n",
      "< Testing Data >\n",
      "< Count by values features >\n",
      "< Input words stats features >\n",
      "< Numerical columns features >\n",
      "< Categorical columns features >\n",
      "< Idle time features >\n",
      "< P-bursts features >\n",
      "< R-bursts features >\n",
      "Engineering time data\n",
      "Engineering cursor position data\n",
      "Engineering word count data\n",
      "Engineering statistical summaries for features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 69.44it/s, column=cursor_position_change1, method=skew]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering activity counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 20197.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering event counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 21732.15it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 23215.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering text change counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 23921.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering punctuation counts data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 27533.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering input words data\n",
      "Engineering ratios data\n",
      "< Learning and Evaluation >\n",
      "Epoch: 1 Fold: 1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 44566\n",
      "[LightGBM] [Info] Number of data points in the train set: 2223, number of used features: 238\n",
      "[LightGBM] [Info] Start training from score 3.706928\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid_0's rmse: 0.557896\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 44591\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 238\n",
      "[LightGBM] [Info] Start training from score 3.713579\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[446]\tvalid_0's rmse: 0.516865\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 44536\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 238\n",
      "[LightGBM] [Info] Start training from score 3.715378\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's rmse: 0.677035\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 4\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 44544\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 238\n",
      "[LightGBM] [Info] Start training from score 3.709982\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[365]\tvalid_0's rmse: 0.613353\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 5\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 44575\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 238\n",
      "[LightGBM] [Info] Start training from score 3.705036\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's rmse: 0.594981\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 6\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003996 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 44546\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 238\n",
      "[LightGBM] [Info] Start training from score 3.707284\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[915]\tvalid_0's rmse: 0.594288\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 7\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 44576\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 238\n",
      "[LightGBM] [Info] Start training from score 3.717176\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's rmse: 0.637705\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 44579\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 238\n",
      "[LightGBM] [Info] Start training from score 3.702788\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's rmse: 0.643028\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 9\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 44558\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 238\n",
      "[LightGBM] [Info] Start training from score 3.724371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's rmse: 0.631671\n",
      "Evaluated only: rmse\n",
      "Epoch: 1 Fold: 10\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 44564\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 238\n",
      "[LightGBM] [Info] Start training from score 3.709982\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's rmse: 0.577915\n",
      "Evaluated only: rmse\n",
      "Avg Loss: 0.6060589718989081\n",
      "metric LGBM = 0.60606\n",
      "Epoch: 1 Fold: 1\n",
      "Epoch: 1 Fold: 2\n",
      "Epoch: 1 Fold: 3\n",
      "Epoch: 1 Fold: 4\n",
      "Epoch: 1 Fold: 5\n",
      "Epoch: 1 Fold: 6\n",
      "Epoch: 1 Fold: 7\n",
      "Epoch: 1 Fold: 8\n",
      "Epoch: 1 Fold: 9\n",
      "Epoch: 1 Fold: 10\n",
      "Avg Loss: 0.6040554926495344\n",
      "metric XGB = 0.60406\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>2.119704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2222bbbb</td>\n",
       "      <td>1.559793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4444cccc</td>\n",
       "      <td>1.605361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     score\n",
       "0  0000aaaa  2.119704\n",
       "1  2222bbbb  1.559793\n",
       "2  4444cccc  1.605361"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CFG:\n",
    "    is_train_lgbm_model = True\n",
    "    is_train_lgbm_optuna = False\n",
    "    is_train_xgb_model = True\n",
    "    is_train_xgb_optuna = False\n",
    "    is_train_cb_model = False\n",
    "    is_train_cb_optuna = False\n",
    "\n",
    "\n",
    "def q1(x):\n",
    "    return x.quantile(0.25)\n",
    "\n",
    "\n",
    "def q3(x):\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "\n",
    "AGGREGATIONS = ['count', 'mean', 'min', 'max',\n",
    "                'first', 'last', q1, 'median', q3, 'sum']\n",
    "\n",
    "WORD_AGGREGATIONS = ['count', 'mean', 'max', q1, 'median', q3, 'sum']\n",
    "\n",
    "num_cols = ['down_time', 'up_time', 'action_time',\n",
    "            'cursor_position', 'word_count']\n",
    "\n",
    "activities = ['Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste']\n",
    "\n",
    "events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft',\n",
    "          '.', ',', 'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']\n",
    "\n",
    "text_changes = ['q', ' ', '.', ',', '\\n', \"'\",\n",
    "                '\"', '-', '?', ';', '=', '/', '\\\\', ':']\n",
    "\n",
    "\n",
    "def count_by_values(df, colname, values):\n",
    "    fts = df.select(pl.col('id').unique(maintain_order=True))\n",
    "    for i, value in enumerate(values):\n",
    "        tmp_df = df.group_by('id').agg(pl.col(colname).is_in(\n",
    "            [value]).sum().alias(f'{colname}_{i}_cnt'))\n",
    "        fts = fts.join(tmp_df, on='id', how='left')\n",
    "    return fts\n",
    "\n",
    "\n",
    "def dev_feats(df):\n",
    "\n",
    "    print(\"< Count by values features >\")\n",
    "\n",
    "    feats = count_by_values(df, 'activity', activities)\n",
    "    feats = feats.join(count_by_values(df, 'text_change',\n",
    "                       text_changes), on='id', how='left')\n",
    "    feats = feats.join(count_by_values(\n",
    "        df, 'down_event', events), on='id', how='left')\n",
    "    feats = feats.join(count_by_values(\n",
    "        df, 'up_event', events), on='id', how='left')\n",
    "\n",
    "    print(\"< Input words stats features >\")\n",
    "\n",
    "    temp = df.filter((~pl.col('text_change').str.contains('=>'))\n",
    "                     & (pl.col('text_change') != 'NoChange'))\n",
    "    temp = temp.group_by('id').agg(\n",
    "        pl.col('text_change').str.concat('').str.extract_all(r'q+'))\n",
    "    temp = temp.with_columns(\n",
    "        input_word_count=pl.col('text_change').list.lengths(),\n",
    "        input_word_length_mean=pl.col('text_change').apply(\n",
    "            lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0)\n",
    "        ),\n",
    "        input_word_length_max=pl.col('text_change').apply(\n",
    "            lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0)\n",
    "        ),\n",
    "        input_word_length_std=pl.col('text_change').apply(\n",
    "            lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0)\n",
    "        ),\n",
    "        input_word_length_median=pl.col('text_change').apply(\n",
    "            lambda x: np.median([len(i) for i in x] if len(x) > 0 else 0)\n",
    "        ),\n",
    "        input_word_length_skew=pl.col('text_change').apply(\n",
    "            lambda x: skew([len(i) for i in x] if len(x) > 0 else 0)\n",
    "        )\n",
    "    )\n",
    "    temp = temp.drop('text_change')\n",
    "    feats = feats.join(temp, on='id', how='left')\n",
    "\n",
    "    print(\"< Numerical columns features >\")\n",
    "\n",
    "    temp = df.group_by(\"id\").agg(\n",
    "        pl.sum('action_time').suffix('_sum'),\n",
    "        pl.mean(num_cols).suffix('_mean'),\n",
    "        pl.std(num_cols).suffix('_std'),\n",
    "        pl.median(num_cols).suffix('_median'),\n",
    "        pl.min(num_cols).suffix('_min'),\n",
    "        pl.max(num_cols).suffix('_max'),\n",
    "        pl.quantile(num_cols, 0.25).suffix('_quantile25'),\n",
    "        pl.quantile(num_cols, 0.75).suffix('_quantile75')\n",
    "    )\n",
    "    feats = feats.join(temp, on='id', how='left')\n",
    "\n",
    "    print(\"< Categorical columns features >\")\n",
    "\n",
    "    temp = df.group_by(\"id\").agg(\n",
    "        pl.n_unique(['activity', 'down_event', 'up_event', 'text_change'])\n",
    "    )\n",
    "    feats = feats.join(temp, on='id', how='left')\n",
    "\n",
    "    print(\"< Idle time features >\")\n",
    "\n",
    "    temp = df.with_columns(pl.col('up_time').shift().over(\n",
    "        'id').alias('up_time_lagged'))\n",
    "    temp = temp.with_columns((abs(pl.col(\n",
    "        'down_time') - pl.col('up_time_lagged')) / 1000).fill_null(0).alias('time_diff'))\n",
    "    temp = temp.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "    temp = temp.group_by(\"id\").agg(\n",
    "        inter_key_largest_lantency=pl.max('time_diff'),\n",
    "        inter_key_median_lantency=pl.median('time_diff'),\n",
    "        mean_pause_time=pl.mean('time_diff'),\n",
    "        std_pause_time=pl.std('time_diff'),\n",
    "        total_pause_time=pl.sum('time_diff'),\n",
    "        pauses_zero_sec=pl.col('time_diff').filter(  # 新增特征\n",
    "            pl.col('time_diff') < 0.5\n",
    "        ).count(),\n",
    "        pauses_half_sec=pl.col('time_diff').filter(\n",
    "            (pl.col('time_diff') > 0.5) & (pl.col('time_diff') < 1)\n",
    "        ).count(),\n",
    "        pauses_1_sec=pl.col('time_diff').filter(\n",
    "            (pl.col('time_diff') > 1) & (pl.col('time_diff') < 1.5)\n",
    "        ).count(),\n",
    "        pauses_1_half_sec=pl.col('time_diff').filter(\n",
    "            (pl.col('time_diff') > 1.5) & (pl.col('time_diff') < 2)\n",
    "        ).count(),\n",
    "        pauses_2_sec=pl.col('time_diff').filter(\n",
    "            (pl.col('time_diff') > 2) & (pl.col('time_diff') < 3)\n",
    "        ).count(),\n",
    "        pauses_3_sec=pl.col('time_diff').filter(\n",
    "            pl.col('time_diff') > 3\n",
    "        ).count()\n",
    "    )\n",
    "    feats = feats.join(temp, on='id', how='left')\n",
    "\n",
    "    print(\"< P-bursts features >\")\n",
    "\n",
    "    temp = df.with_columns(pl.col('up_time').shift().over(\n",
    "        'id').alias('up_time_lagged'))\n",
    "    temp = temp.with_columns((abs(pl.col(\n",
    "        'down_time') - pl.col('up_time_lagged')) / 1000).fill_null(0).alias('time_diff'))\n",
    "    temp = temp.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "    temp = temp.with_columns(pl.col('time_diff') < 2)\n",
    "    temp = temp.with_columns(pl.when(pl.col(\"time_diff\") & pl.col(\"time_diff\").is_last(\n",
    "    )).then(pl.count()).over(pl.col(\"time_diff\").rle_id()).alias('P-bursts'))\n",
    "    temp = temp.drop_nulls()\n",
    "    temp = temp.group_by(\"id\").agg(\n",
    "        pl.mean('P-bursts').suffix('_mean'),\n",
    "        pl.std('P-bursts').suffix('_std'),\n",
    "        pl.count('P-bursts').suffix('_count'),\n",
    "        pl.median('P-bursts').suffix('_median'),\n",
    "        pl.max('P-bursts').suffix('_max'),\n",
    "        pl.first('P-bursts').suffix('_first'),\n",
    "        pl.last('P-bursts').suffix('_last')\n",
    "    )\n",
    "    feats = feats.join(temp, on='id', how='left')\n",
    "\n",
    "    print(\"< R-bursts features >\")\n",
    "\n",
    "    temp = df.filter(pl.col('activity').is_in(['Input', 'Remove/Cut']))\n",
    "    temp = temp.with_columns(pl.col('activity').is_in(['Remove/Cut']))\n",
    "    temp = temp.with_columns(pl.when(pl.col(\"activity\") & pl.col(\"activity\").is_last(\n",
    "    )).then(pl.count()).over(pl.col(\"activity\").rle_id()).alias('R-bursts'))\n",
    "    temp = temp.drop_nulls()\n",
    "    temp = temp.group_by(\"id\").agg(\n",
    "        pl.mean('R-bursts').suffix('_mean'),\n",
    "        pl.std('R-bursts').suffix('_std'),\n",
    "        pl.median('R-bursts').suffix('_median'),\n",
    "        pl.max('R-bursts').suffix('_max'),\n",
    "        pl.first('R-bursts').suffix('_first'),\n",
    "        pl.last('R-bursts').suffix('_last')\n",
    "    )\n",
    "    feats = feats.join(temp, on='id', how='left')\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "def reconstruct_essay(currTextInput):\n",
    "    essayText = \"\"\n",
    "    for Input in currTextInput.values:\n",
    "        if Input[0] == 'Replace':\n",
    "            replaceTxt = Input[2].split(' => ')\n",
    "            essayText = essayText[:Input[1] - len(replaceTxt[1])] + replaceTxt[1] + \\\n",
    "                essayText[Input[1] - len(replaceTxt[1]) + len(replaceTxt[0]):]\n",
    "            continue\n",
    "        if Input[0] == 'Paste':\n",
    "            essayText = essayText[:Input[1] - len(Input[2])] + \\\n",
    "                Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "            continue\n",
    "        if Input[0] == 'Remove/Cut':\n",
    "            essayText = essayText[:Input[1]] + \\\n",
    "                essayText[Input[1] + len(Input[2]):]\n",
    "            continue\n",
    "        if \"M\" in Input[0]:\n",
    "            croppedTxt = Input[0][10:]\n",
    "            splitTxt = croppedTxt.split(' To ')\n",
    "            valueArr = [item.split(', ') for item in splitTxt]\n",
    "            moveData = (int(valueArr[0][0][1:]), int(\n",
    "                valueArr[0][1][:-1]), int(valueArr[1][0][1:]), int(valueArr[1][1][:-1]))\n",
    "            if moveData[0] != moveData[2]:\n",
    "                if moveData[0] < moveData[2]:\n",
    "                    essayText = essayText[:moveData[0]] + \\\n",
    "                        essayText[moveData[1]:moveData[3]] + \\\n",
    "                        essayText[moveData[0]:moveData[1]] + \\\n",
    "                        essayText[moveData[3]:]\n",
    "                else:\n",
    "                    essayText = essayText[:moveData[2]] + \\\n",
    "                        essayText[moveData[0]:moveData[1]] + \\\n",
    "                        essayText[moveData[2]:moveData[0]] + \\\n",
    "                        essayText[moveData[1]:]\n",
    "            continue\n",
    "        essayText = essayText[:Input[1] - len(Input[2])] + \\\n",
    "            Input[2] + essayText[Input[1] - len(Input[2]):]\n",
    "    return essayText\n",
    "\n",
    "\n",
    "def get_essay_df(df):\n",
    "    df = df[df.activity != 'Nonproduction']\n",
    "    temp = df.groupby('id').apply(lambda x: reconstruct_essay(\n",
    "        x[['activity', 'cursor_position', 'text_change']]))\n",
    "    essay_df = pd.DataFrame({'id': df['id'].unique().tolist()})\n",
    "    essay_df = essay_df.merge(temp.rename('essay'), on='id')\n",
    "    return essay_df\n",
    "\n",
    "\n",
    "def word_feats(df):\n",
    "    df['word'] = df['essay'].apply(lambda x: re.split(' |\\\\n|\\\\.|\\\\?|\\\\!', x))\n",
    "    df = df.explode('word')\n",
    "    df['word_len'] = df['word'].apply(lambda x: len(x))\n",
    "    df = df[df['word_len'] != 0]\n",
    "\n",
    "    word_agg_df = df[['id', 'word_len']].groupby(['id']).agg(AGGREGATIONS)\n",
    "    word_agg_df.columns = ['_'.join(x) for x in word_agg_df.columns]\n",
    "    word_agg_df['id'] = word_agg_df.index\n",
    "    word_agg_df = word_agg_df.reset_index(drop=True)\n",
    "\n",
    "    # print(word_agg_df.shape)\n",
    "\n",
    "    for word_l in [3, 4, 5, 6, 7, 8, 9, 10, 11, 12]:\n",
    "        word_agg_df[f'word_len_ge_{word_l}_count'] = \\\n",
    "            df[df['word_len'] == word_l].groupby(['id']).count().iloc[:, 0]\n",
    "        word_agg_df[f'word_len_ge_{word_l}_count'] = \\\n",
    "            word_agg_df[f'word_len_ge_{word_l}_count'].fillna(0)\n",
    "    word_agg_df = word_agg_df.reset_index(drop=True)\n",
    "\n",
    "    # print(word_agg_df.shape)\n",
    "\n",
    "    return word_agg_df\n",
    "\n",
    "\n",
    "def sent_feats(df):\n",
    "    df['sent'] = df['essay'].apply(lambda x: re.split('\\\\.|\\\\?|\\\\!', x))\n",
    "    df = df.explode('sent')\n",
    "    df['sent'] = df['sent'].apply(lambda x: x.replace('\\n', '').strip())\n",
    "    # Number of characters in sentences\n",
    "    df['sent_len'] = df['sent'].apply(lambda x: len(x))\n",
    "    # Number of words in sentences\n",
    "    df['sent_word_count'] = df['sent'].apply(lambda x: len(x.split(' ')))\n",
    "    df = df[df.sent_len != 0].reset_index(drop=True)\n",
    "\n",
    "    sent_agg_df = pd.concat([df[['id', 'sent_len']].groupby(['id']).agg(AGGREGATIONS),\n",
    "                             df[['id', 'sent_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1)\n",
    "    sent_agg_df.columns = ['_'.join(x) for x in sent_agg_df.columns]\n",
    "    sent_agg_df['id'] = sent_agg_df.index\n",
    "    sent_agg_df = sent_agg_df.reset_index(drop=True)\n",
    "    sent_agg_df.drop(columns=[\"sent_word_count_count\"], inplace=True)\n",
    "    sent_agg_df = sent_agg_df.rename(columns={\"sent_len_count\": \"sent_count\"})\n",
    "    return sent_agg_df\n",
    "\n",
    "\n",
    "def parag_feats(df):\n",
    "    df['paragraph'] = df['essay'].apply(lambda x: x.split('\\n'))\n",
    "    df = df.explode('paragraph')\n",
    "    # Number of characters in paragraphs\n",
    "    df['paragraph_len'] = df['paragraph'].apply(lambda x: len(x))\n",
    "    # Number of words in paragraphs\n",
    "    df['paragraph_word_count'] = df['paragraph'].apply(\n",
    "        lambda x: len(x.split(' ')))\n",
    "    df = df[df.paragraph_len != 0].reset_index(drop=True)\n",
    "\n",
    "    paragraph_agg_df = pd.concat([df[['id', 'paragraph_len']].groupby(['id']).agg(AGGREGATIONS),\n",
    "                                  df[['id', 'paragraph_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1)\n",
    "    paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n",
    "    paragraph_agg_df['id'] = paragraph_agg_df.index\n",
    "    paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n",
    "    paragraph_agg_df.drop(columns=[\"paragraph_word_count_count\"], inplace=True)\n",
    "    paragraph_agg_df = paragraph_agg_df.rename(\n",
    "        columns={\"paragraph_len_count\": \"paragraph_count\"})\n",
    "    return paragraph_agg_df\n",
    "\n",
    "\n",
    "def product_to_keys(logs, essays):\n",
    "    essays['product_len'] = essays.essay.str.len()\n",
    "    tmp_df = logs[logs.activity.isin(['Input', 'Remove/Cut'])].groupby(['id']).agg(\n",
    "        {'activity': 'count'}).reset_index().rename(columns={'activity': 'keys_pressed'})\n",
    "    essays = essays.merge(tmp_df, on='id', how='left')\n",
    "    essays['product_to_keys'] = essays['product_len'] / essays['keys_pressed']\n",
    "    return essays[['id', 'product_to_keys']]\n",
    "\n",
    "\n",
    "def get_keys_pressed_per_second(logs):\n",
    "    temp_df = logs[logs['activity'].isin(['Input', 'Remove/Cut'])].groupby(\n",
    "        ['id']).agg(keys_pressed=('event_id', 'count')).reset_index()\n",
    "    temp_df_2 = logs.groupby(['id']).agg(min_down_time=(\n",
    "        'down_time', 'min'), max_up_time=('up_time', 'max')).reset_index()\n",
    "    temp_df = temp_df.merge(temp_df_2, on='id', how='left')\n",
    "    temp_df['keys_per_second'] = temp_df['keys_pressed'] / \\\n",
    "        ((temp_df['max_up_time'] - temp_df['min_down_time']) / 1000)\n",
    "    return temp_df[['id', 'keys_per_second']]\n",
    "\n",
    "\n",
    "preprocessor = Preprocessor(seed=42)\n",
    "\n",
    "data_path = '/kaggle/input/linking-writing-processes-to-writing-quality/'\n",
    "train_logs = pl.scan_csv(data_path + 'train_logs.csv')\n",
    "train_feats = dev_feats(train_logs)\n",
    "train_feats = train_feats.collect().to_pandas()\n",
    "train_logs = train_logs.collect().to_pandas()\n",
    "\n",
    "print('< Main Processor >')\n",
    "train_feats = train_feats.merge(\n",
    "    preprocessor.make_feats(train_logs), on='id', how='left')\n",
    "\n",
    "print('< Essay Reconstruction >')\n",
    "train_essays = get_essay_df(train_logs)\n",
    "train_feats = train_feats.merge(word_feats(train_essays), on='id', how='left')\n",
    "train_feats = train_feats.merge(sent_feats(train_essays), on='id', how='left')\n",
    "train_feats = train_feats.merge(parag_feats(train_essays), on='id', how='left')\n",
    "train_feats = train_feats.merge(\n",
    "    get_keys_pressed_per_second(train_logs), on='id', how='left')\n",
    "train_feats = train_feats.merge(product_to_keys(\n",
    "    train_logs, train_essays), on='id', how='left')\n",
    "\n",
    "\n",
    "train_feats['word_time_ratio'] = train_feats['word_count_max'] / \\\n",
    "    train_feats['up_time_max']\n",
    "train_feats['position_time_ratio'] = train_feats['cursor_position_max'] / \\\n",
    "    train_feats['up_time_max']\n",
    "train_feats['word_per_action_time'] = train_feats['word_count_max'] / \\\n",
    "    train_feats['action_time_sum']\n",
    "train_feats['position_per_action_time'] = train_feats['cursor_position_max'] / \\\n",
    "    train_feats['action_time_sum']\n",
    "\n",
    "print('< Mapping >')\n",
    "train_scores = pd.read_csv(data_path + 'train_scores.csv')\n",
    "data = train_feats.merge(train_scores, on='id', how='left')\n",
    "data.to_csv(\"baseline_features.csv\", index=False)\n",
    "\n",
    "x = data.drop(['id', 'score'], axis=1)\n",
    "y = data['score'].values\n",
    "print(f'Number of features: {len(x.columns)}')\n",
    "\n",
    "\n",
    "print('< Testing Data >')\n",
    "test_logs = pl.scan_csv(data_path + 'test_logs.csv')\n",
    "test_feats = dev_feats(test_logs)\n",
    "test_feats = test_feats.collect().to_pandas()\n",
    "test_logs = test_logs.collect().to_pandas()\n",
    "\n",
    "test_essays = get_essay_df(test_logs)\n",
    "test_feats = test_feats.merge(\n",
    "    preprocessor.make_feats(test_logs), on='id', how='left')\n",
    "test_feats = test_feats.merge(word_feats(test_essays), on='id', how='left')\n",
    "test_feats = test_feats.merge(sent_feats(test_essays), on='id', how='left')\n",
    "test_feats = test_feats.merge(parag_feats(test_essays), on='id', how='left')\n",
    "test_feats = test_feats.merge(\n",
    "    get_keys_pressed_per_second(test_logs), on='id', how='left')\n",
    "test_feats = test_feats.merge(product_to_keys(\n",
    "    test_logs, test_essays), on='id', how='left')\n",
    "\n",
    "test_feats['word_time_ratio'] = test_feats['word_count_max'] / \\\n",
    "    test_feats['up_time_max']\n",
    "test_feats['position_time_ratio'] = test_feats['cursor_position_max'] / \\\n",
    "    test_feats['up_time_max']\n",
    "test_feats['word_per_action_time'] = test_feats['word_count_max'] / \\\n",
    "    test_feats['action_time_sum']\n",
    "test_feats['position_per_action_time'] = test_feats['cursor_position_max'] / \\\n",
    "    test_feats['action_time_sum']\n",
    "\n",
    "test_ids = test_feats['id'].values\n",
    "testin_x = test_feats.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "def train_valid_split(data_x, data_y, train_idx, valid_idx):\n",
    "    x_train = data_x.iloc[train_idx]\n",
    "    y_train = data_y[train_idx]\n",
    "    x_valid = data_x.iloc[valid_idx]\n",
    "    y_valid = data_y[valid_idx]\n",
    "    return x_train, y_train, x_valid, y_valid\n",
    "\n",
    "\n",
    "def evaluate(data_x, data_y, model, random_state=42, n_splits=5, test_x=None):\n",
    "    skf = model_selection.StratifiedKFold(\n",
    "        n_splits=n_splits, random_state=random_state, shuffle=True\n",
    "    )\n",
    "    test_y = np.zeros(len(data_x)) if (\n",
    "        test_x is None) else np.zeros((len(test_x), n_splits))\n",
    "    for i, (train_index, valid_index) in enumerate(skf.split(data_x, data_y.astype(str))):\n",
    "        train_x, train_y, valid_x, valid_y = train_valid_split(\n",
    "            data_x, data_y, train_index, valid_index)\n",
    "        model.fit(train_x, train_y)\n",
    "        if test_x is None:\n",
    "            test_y[valid_index] = model.predict(valid_x)\n",
    "        else:\n",
    "            test_y[:, i] = model.predict(test_x)\n",
    "    return test_y if (test_x is None) else np.mean(test_y, axis=1)\n",
    "\n",
    "\n",
    "target_col = ['score']\n",
    "drop_cols = ['id']\n",
    "train_cols = [\n",
    "    col for col in train_feats.columns if col not in target_col + drop_cols\n",
    "]\n",
    "\n",
    "print('< Learning and Evaluation >')\n",
    "\n",
    "\n",
    "def train_lgbm_model(train_feats, test_feats):\n",
    "    TEST_PREDS = np.zeros((len(test_feats), 1))\n",
    "\n",
    "    os.makedirs('../baseline_lgb_models', exist_ok=True)\n",
    "\n",
    "    EPOCHS = 1\n",
    "    SPLIT = 10\n",
    "\n",
    "    test_prediction_list = []\n",
    "    model_dict = {}\n",
    "    scores = []\n",
    "    preds = np.zeros((len(train_feats), 1))\n",
    "\n",
    "    best_params = {\n",
    "        \"reg_alpha\": 0.6399538277231696,\n",
    "        \"reg_lambda\": 3.2328525092312117,\n",
    "        \"colsample_bytree\": 0.42507773805738647,\n",
    "        \"subsample\": 0.8922549415295282,\n",
    "        \"learning_rate\": 0.034821754701046356,\n",
    "        \"num_leaves\": 11,\n",
    "        \"max_depth\": 8,\n",
    "        \"min_child_samples\": 19,\n",
    "        \"n_estimators\": 9561,\n",
    "        'n_jobs': 4\n",
    "    }\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "        kf = model_selection.KFold(\n",
    "            n_splits=SPLIT, random_state=42 + i * 10, shuffle=True)\n",
    "        valid_preds = np.zeros(train_feats.shape[0])\n",
    "        X_test = test_feats[train_cols]\n",
    "\n",
    "        for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "            print(f'Epoch: {i + 1} Fold: {fold + 1}')\n",
    "            X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "            X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "            params = {\n",
    "                \"objective\": \"regression\",\n",
    "                \"metric\": \"rmse\",\n",
    "                \"random_state\": 42,\n",
    "                \"verbosity\": 1,\n",
    "                **best_params\n",
    "            }\n",
    "            model = lgb.LGBMRegressor(**params)\n",
    "            early_stopping_callback = lgb.early_stopping(\n",
    "                100, first_metric_only=True, verbose=True)\n",
    "\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_valid, y_valid)],\n",
    "                callbacks=[early_stopping_callback]\n",
    "            )\n",
    "\n",
    "            valid_predict = model.predict(X_valid)\n",
    "            valid_preds[valid_idx] = valid_predict\n",
    "            preds[valid_idx, 0] += valid_predict / EPOCHS\n",
    "\n",
    "            test_predict = model.predict(X_test)\n",
    "            TEST_PREDS[:, 0] += test_predict / EPOCHS / SPLIT\n",
    "            test_prediction_list.append(test_predict)\n",
    "\n",
    "            score = metrics.mean_squared_error(\n",
    "                y_valid, valid_predict, squared=False)\n",
    "            model_dict[f'Epoch{i + 1}-Fold{fold + 1}'] = model\n",
    "            model.booster_.save_model(\n",
    "                f'../baseline_lgb_models/lgbm_model_epoch{i + 1}_fold{fold + 1}.txt')\n",
    "\n",
    "        final_score = metrics.mean_squared_error(\n",
    "            train_feats[target_col], valid_preds, squared=False)\n",
    "        scores.append(final_score)\n",
    "\n",
    "    print(\"Avg Loss:\", np.mean(scores))\n",
    "\n",
    "    print('metric LGBM = {:.5f}'.format(metrics.mean_squared_error(\n",
    "        train_feats[target_col], preds[:, 0], squared=False)))\n",
    "\n",
    "    return TEST_PREDS\n",
    "\n",
    "\n",
    "def train_xgb_model(train_feats, test_feats):\n",
    "    TEST_PREDS = np.zeros((len(test_feats), 1))\n",
    "\n",
    "    os.makedirs('../baseline_xgb_models', exist_ok=True)\n",
    "\n",
    "    EPOCHS = 1\n",
    "    SPLIT = 10\n",
    "\n",
    "    test_prediction_list = []\n",
    "    model_dict = {}\n",
    "    scores = []\n",
    "    preds = np.zeros((len(train_feats), 1))\n",
    "\n",
    "    best_params = {\n",
    "        \"reg_alpha\": 0.6560074908076096,\n",
    "        \"reg_lambda\": 1.561799487709162,\n",
    "        \"colsample_bytree\": 0.8203962287319901,\n",
    "        \"subsample\": 0.40422380528341667,\n",
    "        \"learning_rate\": 0.007215362979549649,\n",
    "        \"max_depth\": 5,\n",
    "        \"min_child_weight\": 1.2595611164627434,\n",
    "        \"gamma\": 1.1514967757811019,\n",
    "        \"max_delta_step\": 3,\n",
    "        \"n_estimators\": 12180,\n",
    "        'n_jobs': 4\n",
    "    }\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "        kf = model_selection.KFold(\n",
    "            n_splits=SPLIT, random_state=42 + i * 10, shuffle=True)\n",
    "        valid_preds = np.zeros(train_feats.shape[0])\n",
    "        X_test = test_feats[train_cols]\n",
    "\n",
    "        for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "            print(f'Epoch: {i + 1} Fold: {fold + 1}')\n",
    "            X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "            X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "            params = {\n",
    "                \"objective\": \"reg:squarederror\",\n",
    "                \"eval_metric\": \"rmse\",\n",
    "                \"random_state\": 42,\n",
    "                \"verbosity\": 0,\n",
    "                **best_params\n",
    "            }\n",
    "            model = xgb.XGBRegressor(**params)\n",
    "\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_valid, y_valid)],\n",
    "                early_stopping_rounds=100,\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            valid_predict = model.predict(X_valid)\n",
    "            valid_preds[valid_idx] = valid_predict\n",
    "            preds[valid_idx, 0] += valid_predict / EPOCHS\n",
    "\n",
    "            test_predict = model.predict(X_test)\n",
    "            TEST_PREDS[:, 0] += test_predict / EPOCHS / SPLIT\n",
    "            test_prediction_list.append(test_predict)\n",
    "\n",
    "            score = metrics.mean_squared_error(\n",
    "                y_valid, valid_predict, squared=False)\n",
    "            model_dict[f'Epoch{i + 1}-Fold{fold + 1}'] = model\n",
    "            model.save_model(\n",
    "                f'../baseline_xgb_models/xgb_model_epoch{i + 1}_fold{fold + 1}.json')\n",
    "            # model.load_model(f'../baseline_xgb_models/xgb_model_epoch{i + 1}_fold{fold + 1}.json')\n",
    "\n",
    "        final_score = metrics.mean_squared_error(\n",
    "            train_feats[target_col], valid_preds, squared=False)\n",
    "        scores.append(final_score)\n",
    "\n",
    "    print(\"Avg Loss:\", np.mean(scores))\n",
    "\n",
    "    print('metric XGB = {:.5f}'.format(metrics.mean_squared_error(\n",
    "        train_feats[target_col], preds[:, 0], squared=False)))\n",
    "\n",
    "    return TEST_PREDS\n",
    "\n",
    "\n",
    "def train_cb_model(train_feats, test_feats):\n",
    "    TEST_PREDS = np.zeros((len(test_feats), 1))\n",
    "\n",
    "    os.makedirs('../baseline_cb_models', exist_ok=True)\n",
    "\n",
    "    EPOCHS = 1\n",
    "    SPLIT = 10\n",
    "\n",
    "    test_prediction_list = []\n",
    "    model_dict = {}\n",
    "    scores = []\n",
    "    preds = np.zeros((len(train_feats), 1))\n",
    "\n",
    "    best_params = {\n",
    "        'l2_leaf_reg': 3.8071290717767194,\n",
    "        'colsample_bylevel': 0.45216556596658897,\n",
    "        'subsample': 0.4832292138435902,\n",
    "        'learning_rate': 0.002,\n",
    "        'depth': 6,\n",
    "        'thread_count': 4,\n",
    "        'min_child_samples': 7,\n",
    "        'iterations': 11_861,\n",
    "    }\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "        kf = model_selection.KFold(\n",
    "            n_splits=SPLIT, random_state=42 + i * 10, shuffle=True)\n",
    "        valid_preds = np.zeros(train_feats.shape[0])\n",
    "        X_test = test_feats[train_cols]\n",
    "\n",
    "        for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "            print(f'Epoch: {i + 1} Fold: {fold + 1}')\n",
    "            X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "            X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "\n",
    "            model = cb.CatBoostRegressor(\n",
    "                loss_function='RMSE',\n",
    "                random_seed=2023,\n",
    "                verbose=True,\n",
    "                **best_params\n",
    "            )\n",
    "\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_valid, y_valid)],\n",
    "                early_stopping_rounds=100,\n",
    "                verbose=True\n",
    "            )\n",
    "\n",
    "            valid_predict = model.predict(X_valid)\n",
    "            valid_preds[valid_idx] = valid_predict\n",
    "            preds[valid_idx, 0] += valid_predict / EPOCHS\n",
    "\n",
    "            test_predict = model.predict(X_test)\n",
    "            TEST_PREDS[:, 0] += test_predict / EPOCHS / SPLIT\n",
    "            test_prediction_list.append(test_predict)\n",
    "\n",
    "            score = metrics.mean_squared_error(\n",
    "                y_valid, valid_predict, squared=False)\n",
    "            model_dict[f'Epoch{i + 1}-Fold{fold + 1}'] = model\n",
    "            model.save_model(\n",
    "                f'../baseline_cb_models/cb_model_epoch{i + 1}_fold{fold + 1}.cbm')\n",
    "            # model.load_model(f'../baseline_cb_models/cb_model_epoch{i + 1}_fold{fold + 1}.cbm')\n",
    "\n",
    "        final_score = metrics.mean_squared_error(\n",
    "            train_feats[target_col], valid_preds, squared=False)\n",
    "        scores.append(final_score)\n",
    "\n",
    "    print(\"Avg Loss:\", np.mean(scores))\n",
    "\n",
    "    print('metric CB = {:.5f}'.format(metrics.mean_squared_error(\n",
    "        train_feats[target_col], preds[:, 0], squared=False)))\n",
    "\n",
    "    return TEST_PREDS\n",
    "\n",
    "\n",
    "def train_lgbm_optuna(train_feats):\n",
    "    os.makedirs('../baseline_lgb_models_optuna', exist_ok=True)\n",
    "\n",
    "    def objective(trial):\n",
    "        EPOCHS = 1\n",
    "        SPLIT = 10\n",
    "\n",
    "        model_dict = {}\n",
    "        scores = []\n",
    "        preds = np.zeros((len(train_feats), 1))\n",
    "\n",
    "        best_params = {\n",
    "            'reg_alpha': trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "            'reg_lambda': trial.suggest_float(\"reg_lambda\", 0.0, 5.0),\n",
    "            'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "            'subsample': trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "            'learning_rate': trial.suggest_float(\"learning_rate\", 1e-4, 1e-1),\n",
    "            'num_leaves': trial.suggest_int(\"num_leaves\", 5, 50),\n",
    "            'max_depth': trial.suggest_int(\"max_depth\", 5, 30),\n",
    "            'min_child_samples': trial.suggest_int(\"min_child_samples\", 2, 30),\n",
    "            'n_jobs': 4,\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 1000, 20000)\n",
    "        }\n",
    "\n",
    "        for i in range(EPOCHS):\n",
    "            kf = model_selection.KFold(\n",
    "                n_splits=SPLIT, random_state=42 + i * 10, shuffle=True)\n",
    "            valid_preds = np.zeros(train_feats.shape[0])\n",
    "\n",
    "            for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "                print(f'Epoch: {i + 1} Fold: {fold + 1}')\n",
    "                X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "                X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "                params = {\n",
    "                    \"objective\": \"regression\",\n",
    "                    \"metric\": \"rmse\",\n",
    "                    \"random_state\": 42,\n",
    "                    \"verbosity\": -1,\n",
    "                    **best_params\n",
    "                }\n",
    "                model = lgb.LGBMRegressor(**params)\n",
    "                early_stopping_callback = lgb.early_stopping(\n",
    "                    100, first_metric_only=True, verbose=False\n",
    "                )\n",
    "\n",
    "                model.fit(\n",
    "                    X_train, y_train,\n",
    "                    eval_set=[(X_valid, y_valid)],\n",
    "                    callbacks=[early_stopping_callback]\n",
    "                )\n",
    "\n",
    "                valid_predict = model.predict(X_valid)\n",
    "                valid_preds[valid_idx] = valid_predict\n",
    "                preds[valid_idx, 0] += valid_predict / EPOCHS\n",
    "\n",
    "                score = metrics.mean_squared_error(\n",
    "                    y_valid, valid_predict, squared=False)\n",
    "                model_dict[f'Epoch{i + 1}-Fold{fold + 1}'] = model\n",
    "                model.booster_.save_model(\n",
    "                    f'../baseline_lgb_models_optuna/lgbm_model_epoch{i + 1}_fold{fold + 1}.txt')\n",
    "\n",
    "            final_score = metrics.mean_squared_error(\n",
    "                train_feats[target_col], valid_preds, squared=False)\n",
    "            scores.append(final_score)\n",
    "\n",
    "        print(\"Avg Loss:\", np.mean(scores))\n",
    "        return np.mean(scores)\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    print(\"LightGBM Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"Value: {trial.value}\")\n",
    "    print(\"Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    with open('lgbm_best_params.json', 'w') as json_file:\n",
    "        json.dump(trial.params, json_file, indent=4)\n",
    "\n",
    "    print(\"Save LightGBM best_params to json file\")\n",
    "\n",
    "\n",
    "def train_xgb_optuna(train_feats):\n",
    "    os.makedirs('../baseline_xgb_models_optuna', exist_ok=True)\n",
    "\n",
    "    def objective(trial):\n",
    "        EPOCHS = 1\n",
    "        SPLIT = 10\n",
    "\n",
    "        model_dict = {}\n",
    "        scores = []\n",
    "        preds = np.zeros((len(train_feats), 1))\n",
    "\n",
    "        best_params = {\n",
    "            'reg_alpha': trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "            'reg_lambda': trial.suggest_float(\"reg_lambda\", 0.0, 5.0),\n",
    "            'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "            'subsample': trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "            'learning_rate': trial.suggest_float(\"learning_rate\", 1e-4, 1e-1),\n",
    "            'max_depth': trial.suggest_int(\"max_depth\", 5, 30),\n",
    "            'min_child_weight': trial.suggest_float(\"min_child_weight\", 1.0, 5.0),\n",
    "            'gamma': trial.suggest_float(\"gamma\", 0.0, 10.0),\n",
    "            'max_delta_step': trial.suggest_int(\"max_delta_step\", 1, 5),\n",
    "            'n_jobs': 4,\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 1000, 20000)\n",
    "        }\n",
    "\n",
    "        for i in range(EPOCHS):\n",
    "            kf = model_selection.KFold(\n",
    "                n_splits=SPLIT, random_state=42 + i * 10, shuffle=True\n",
    "            )\n",
    "            valid_preds = np.zeros(train_feats.shape[0])\n",
    "\n",
    "            for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "                print(f'Epoch: {i + 1} Fold: {fold + 1}')\n",
    "                X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "                X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "                params = {\n",
    "                    \"objective\": \"reg:squarederror\",\n",
    "                    \"eval_metric\": \"rmse\",\n",
    "                    \"random_state\": 42,\n",
    "                    \"verbosity\": 0,\n",
    "                    **best_params\n",
    "                }\n",
    "                model = xgb.XGBRegressor(**params)\n",
    "\n",
    "                model.fit(\n",
    "                    X_train, y_train,\n",
    "                    eval_set=[(X_valid, y_valid)],\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose=False\n",
    "                )\n",
    "\n",
    "                valid_predict = model.predict(X_valid)\n",
    "                valid_preds[valid_idx] = valid_predict\n",
    "                preds[valid_idx, 0] += valid_predict / EPOCHS\n",
    "\n",
    "                score = metrics.mean_squared_error(\n",
    "                    y_valid, valid_predict, squared=False)\n",
    "                model_dict[f'Epoch{i + 1}-Fold{fold + 1}'] = model\n",
    "                model.save_model(\n",
    "                    f'../baseline_xgb_models_optuna/xgb_model_epoch{i + 1}_fold{fold + 1}.json')\n",
    "\n",
    "            final_score = metrics.mean_squared_error(\n",
    "                train_feats[target_col], valid_preds, squared=False)\n",
    "            scores.append(final_score)\n",
    "\n",
    "        print(\"Avg Loss:\", np.mean(scores))\n",
    "        return np.mean(scores)\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    print(\"XGBoost Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"Value: {trial.value}\")\n",
    "    print(\"Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    with open('xgb_best_params.json', 'w') as json_file:\n",
    "        json.dump(trial.params, json_file, indent=4)\n",
    "\n",
    "    print(\"Save XGBoost best_params to json file\")\n",
    "\n",
    "\n",
    "def train_cb_optuna(train_feats):\n",
    "    os.makedirs('../baseline_cb_models_optuna', exist_ok=True)\n",
    "\n",
    "    def objective(trial):\n",
    "        EPOCHS = 1\n",
    "        SPLIT = 10\n",
    "\n",
    "        model_dict = {}\n",
    "        scores = []\n",
    "        preds = np.zeros((len(train_feats), 1))\n",
    "\n",
    "        best_params = {\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 10.0),\n",
    "            'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 1.0),\n",
    "            'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True),\n",
    "            'depth': trial.suggest_int('depth', 1, 10),\n",
    "            'iterations': trial.suggest_int('iterations', 1000, 15000),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 1, 20),\n",
    "            'thread_count': 4\n",
    "        }\n",
    "\n",
    "        for i in range(EPOCHS):\n",
    "            kf = model_selection.KFold(\n",
    "                n_splits=SPLIT, random_state=42 + i * 10, shuffle=True)\n",
    "            valid_preds = np.zeros(train_feats.shape[0])\n",
    "\n",
    "            for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "                print(f'Epoch: {i + 1} Fold: {fold + 1}')\n",
    "                X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "                X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "\n",
    "                model = cb.CatBoostRegressor(\n",
    "                    loss_function='RMSE',\n",
    "                    random_seed=2023,\n",
    "                    verbose=False,\n",
    "                    **best_params\n",
    "                )\n",
    "\n",
    "                model.fit(\n",
    "                    X_train, y_train,\n",
    "                    eval_set=[(X_valid, y_valid)],\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose=True\n",
    "                )\n",
    "\n",
    "                valid_predict = model.predict(X_valid)\n",
    "                valid_preds[valid_idx] = valid_predict\n",
    "                preds[valid_idx, 0] += valid_predict / EPOCHS\n",
    "\n",
    "                score = metrics.mean_squared_error(\n",
    "                    y_valid, valid_predict, squared=False)\n",
    "                model_dict[f'Epoch{i + 1}-Fold{fold + 1}'] = model\n",
    "                model.save_model(\n",
    "                    f'../baseline_cb_models_optuna/cb_model_epoch{i + 1}_fold{fold + 1}.cbm')\n",
    "\n",
    "            final_score = metrics.mean_squared_error(\n",
    "                train_feats[target_col], valid_preds, squared=False)\n",
    "            scores.append(final_score)\n",
    "\n",
    "        print(\"Avg Loss:\", np.mean(scores))\n",
    "        return np.mean(scores)\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    print(\"CatBoost Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"Value: {trial.value}\")\n",
    "    print(\"Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    with open('cb_best_params.json', 'w') as json_file:\n",
    "        json.dump(trial.params, json_file, indent=4)\n",
    "\n",
    "    print(\"Save catboost best_params to json file\")\n",
    "\n",
    "\n",
    "if CFG.is_train_lgbm_optuna:\n",
    "    train_lgbm_optuna(train_feats=data)\n",
    "\n",
    "if CFG.is_train_xgb_optuna:\n",
    "    train_xgb_optuna(train_feats=data)\n",
    "\n",
    "if CFG.is_train_cb_optuna:\n",
    "    train_cb_optuna(train_feats=data)\n",
    "\n",
    "if CFG.is_train_lgbm_model:\n",
    "    lgbm_preds = train_lgbm_model(train_feats=data, test_feats=test_feats)\n",
    "\n",
    "if CFG.is_train_xgb_model:\n",
    "    xgb_preds = train_xgb_model(train_feats=data, test_feats=test_feats)\n",
    "\n",
    "if CFG.is_train_cb_model:\n",
    "    cb_preds = train_cb_model(train_feats=data, test_feats=test_feats)\n",
    "\n",
    "weights = [0.5, 0.5]\n",
    "\n",
    "test_preds = np.zeros(test_feats.shape[0])\n",
    "test_preds = lgbm_preds * weights[0] + xgb_preds * weights[1]\n",
    "\n",
    "test_feats['score'] = test_preds\n",
    "sub2 = test_feats[['id', 'score']]\n",
    "sub2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c97272b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-09T06:05:03.580468Z",
     "iopub.status.busy": "2024-01-09T06:05:03.580126Z",
     "iopub.status.idle": "2024-01-09T06:05:03.596058Z",
     "shell.execute_reply": "2024-01-09T06:05:03.595242Z"
    },
    "papermill": {
     "duration": 0.057926,
     "end_time": "2024-01-09T06:05:03.597924",
     "exception": false,
     "start_time": "2024-01-09T06:05:03.539998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>2.161814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2222bbbb</td>\n",
       "      <td>1.618558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4444cccc</td>\n",
       "      <td>1.669106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     score\n",
       "0  0000aaaa  2.161814\n",
       "1  2222bbbb  1.618558\n",
       "2  4444cccc  1.669106"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1.rename(columns={'score': 'score_1'}, inplace=True)\n",
    "sub2.rename(columns={'score': 'score_2'}, inplace=True)\n",
    "submission = pd.merge(sub1, sub2, on='id')\n",
    "submission['score'] = ((submission['score_1'] * (1/2)) + (submission['score_2'] * (1/2)))\n",
    "submission_final = submission[['id', 'score']]\n",
    "submission_final.to_csv('submission.csv', index=False)\n",
    "submission_final"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6678907,
     "sourceId": 59291,
     "sourceType": "competition"
    },
    {
     "datasetId": 3992884,
     "sourceId": 6971449,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3949123,
     "sourceId": 6973319,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 150384981,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 512.310597,
   "end_time": "2024-01-09T06:05:05.362944",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-09T05:56:33.052347",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
