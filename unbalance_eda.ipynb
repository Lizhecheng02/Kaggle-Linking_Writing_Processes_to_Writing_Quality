{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics, model_selection\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs = pd.read_csv(\"train_logs.csv\")\n",
    "train_logs.head()\n",
    "\n",
    "for column in ['down_time', 'action_time', 'up_time']:\n",
    "    train_logs[column] = train_logs[column] / 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022f953</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0042269b</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0059420b</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0075873a</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  score\n",
       "0  001519c8    3.5\n",
       "1  0022f953    3.5\n",
       "2  0042269b    6.0\n",
       "3  0059420b    2.0\n",
       "4  0075873a    4.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores = pd.read_csv(\"train_scores.csv\")\n",
    "train_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores['score'].value_counts().sort_values().plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id0_5 = train_scores[train_scores['score'] == 0.5]['id'].to_list()\n",
    "id1_0 = train_scores[train_scores['score'] == 1.0]['id'].to_list()\n",
    "id1_5 = train_scores[train_scores['score'] == 1.5]['id'].to_list()\n",
    "id2_0 = train_scores[train_scores['score'] == 2.0]['id'].to_list()\n",
    "id2_5 = train_scores[train_scores['score'] == 2.5]['id'].to_list()\n",
    "id3_0 = train_scores[train_scores['score'] == 3.0]['id'].to_list()\n",
    "id3_5 = train_scores[train_scores['score'] == 3.5]['id'].to_list()\n",
    "id4_0 = train_scores[train_scores['score'] == 4.0]['id'].to_list()\n",
    "id4_5 = train_scores[train_scores['score'] == 4.5]['id'].to_list()\n",
    "id5_0 = train_scores[train_scores['score'] == 5.0]['id'].to_list()\n",
    "id5_5 = train_scores[train_scores['score'] == 5.5]['id'].to_list()\n",
    "id6_0 = train_scores[train_scores['score'] == 6.0]['id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231.4\n",
      "218.45714285714286\n",
      "245.85507246376812\n",
      "237.5108695652174\n",
      "257.7014925373134\n",
      "284.44940476190476\n",
      "345.119341563786\n",
      "401.5329341317365\n",
      "481.84328358208955\n",
      "548.6983240223464\n",
      "641.1015625\n",
      "695.7027027027027\n"
     ]
    }
   ],
   "source": [
    "print(train_logs[train_logs['id'].isin(id0_5)].groupby('id')['word_count'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id1_0)].groupby('id')['word_count'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id1_5)].groupby('id')['word_count'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id2_0)].groupby('id')['word_count'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id2_5)].groupby('id')['word_count'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id3_0)].groupby('id')['word_count'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id3_5)].groupby('id')['word_count'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id4_0)].groupby('id')['word_count'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id4_5)].groupby('id')['word_count'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id5_0)].groupby('id')['word_count'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id5_5)].groupby('id')['word_count'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id6_0)].groupby('id')['word_count'].max().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1571.6\n",
      "1852.3714285714286\n",
      "2097.289855072464\n",
      "1997.9239130434783\n",
      "2298.9950248756218\n",
      "2537.8839285714284\n",
      "3015.9732510288068\n",
      "3554.7784431137725\n",
      "4184.850746268657\n",
      "4727.731843575419\n",
      "5504.703125\n",
      "5675.0\n"
     ]
    }
   ],
   "source": [
    "print(train_logs[train_logs['id'].isin(id0_5)].groupby('id')['event_id'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id1_0)].groupby('id')['event_id'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id1_5)].groupby('id')['event_id'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id2_0)].groupby('id')['event_id'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id2_5)].groupby('id')['event_id'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id3_0)].groupby('id')['event_id'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id3_5)].groupby('id')['event_id'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id4_0)].groupby('id')['event_id'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id4_5)].groupby('id')['event_id'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id5_0)].groupby('id')['event_id'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id5_5)].groupby('id')['event_id'].max().mean())\n",
    "print(train_logs[train_logs['id'].isin(id6_0)].groupby('id')['event_id'].max().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id        activity     \n",
      "1ebb9b74  Input            1289\n",
      "          Remove/Cut         93\n",
      "          Nonproduction      19\n",
      "315bdafd  Input            1214\n",
      "          Remove/Cut        130\n",
      "          Nonproduction      35\n",
      "3bda31e6  Input            1426\n",
      "          Remove/Cut        125\n",
      "          Nonproduction      47\n",
      "40b28508  Input            1809\n",
      "          Nonproduction     127\n",
      "          Remove/Cut         61\n",
      "c3663a2d  Input            1186\n",
      "          Nonproduction     270\n",
      "          Remove/Cut         27\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_logs[train_logs['id'].isin(id0_5)].groupby('id')['activity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id        activity     \n",
      "0042269b  Input            3515\n",
      "          Remove/Cut        439\n",
      "          Nonproduction     175\n",
      "          Replace             7\n",
      "044b274d  Input            4653\n",
      "                           ... \n",
      "f9fd3268  Remove/Cut        870\n",
      "          Nonproduction     411\n",
      "fa489e99  Input            8622\n",
      "          Remove/Cut       1238\n",
      "          Nonproduction     286\n",
      "Name: count, Length: 141, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_logs[train_logs['id'].isin(id6_0)].groupby('id')['activity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170.0146\n",
      "195.56257142857143\n",
      "200.04436231884057\n",
      "196.7087608695652\n",
      "229.20283582089553\n",
      "257.8847797619047\n",
      "299.99428395061733\n",
      "354.45059481037924\n",
      "400.3463407960199\n",
      "445.52749720670386\n",
      "532.3988046874999\n",
      "539.6108918918919\n"
     ]
    }
   ],
   "source": [
    "print(train_logs[train_logs['id'].isin(id0_5)].groupby('id')['action_time'].sum().mean())\n",
    "print(train_logs[train_logs['id'].isin(id1_0)].groupby('id')['action_time'].sum().mean())\n",
    "print(train_logs[train_logs['id'].isin(id1_5)].groupby('id')['action_time'].sum().mean())\n",
    "print(train_logs[train_logs['id'].isin(id2_0)].groupby('id')['action_time'].sum().mean())\n",
    "print(train_logs[train_logs['id'].isin(id2_5)].groupby('id')['action_time'].sum().mean())\n",
    "print(train_logs[train_logs['id'].isin(id3_0)].groupby('id')['action_time'].sum().mean())\n",
    "print(train_logs[train_logs['id'].isin(id3_5)].groupby('id')['action_time'].sum().mean())\n",
    "print(train_logs[train_logs['id'].isin(id4_0)].groupby('id')['action_time'].sum().mean())\n",
    "print(train_logs[train_logs['id'].isin(id4_5)].groupby('id')['action_time'].sum().mean())\n",
    "print(train_logs[train_logs['id'].isin(id5_0)].groupby('id')['action_time'].sum().mean())\n",
    "print(train_logs[train_logs['id'].isin(id5_5)].groupby('id')['action_time'].sum().mean())\n",
    "print(train_logs[train_logs['id'].isin(id6_0)].groupby('id')['action_time'].sum().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'event_id', 'down_time', 'up_time', 'action_time', 'activity',\n",
       "       'down_event', 'up_event', 'text_change', 'cursor_position',\n",
       "       'word_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_logs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>max_word_count</th>\n",
       "      <th>max_event_id</th>\n",
       "      <th>max_up_time</th>\n",
       "      <th>sum_action_time</th>\n",
       "      <th>max_cursor_position</th>\n",
       "      <th>word_per_event</th>\n",
       "      <th>word_per_action_time</th>\n",
       "      <th>word_per_total_time</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>256.0</td>\n",
       "      <td>2557.0</td>\n",
       "      <td>1801.969</td>\n",
       "      <td>297.243</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>0.100117</td>\n",
       "      <td>0.861248</td>\n",
       "      <td>0.142067</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022f953</td>\n",
       "      <td>323.0</td>\n",
       "      <td>2454.0</td>\n",
       "      <td>1788.969</td>\n",
       "      <td>275.391</td>\n",
       "      <td>1676.0</td>\n",
       "      <td>0.131622</td>\n",
       "      <td>1.172878</td>\n",
       "      <td>0.180551</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0042269b</td>\n",
       "      <td>404.0</td>\n",
       "      <td>4136.0</td>\n",
       "      <td>1771.669</td>\n",
       "      <td>421.201</td>\n",
       "      <td>2291.0</td>\n",
       "      <td>0.097679</td>\n",
       "      <td>0.959162</td>\n",
       "      <td>0.228034</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0059420b</td>\n",
       "      <td>206.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>1404.469</td>\n",
       "      <td>189.596</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>0.132391</td>\n",
       "      <td>1.086521</td>\n",
       "      <td>0.146675</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0075873a</td>\n",
       "      <td>252.0</td>\n",
       "      <td>2531.0</td>\n",
       "      <td>1662.472</td>\n",
       "      <td>313.702</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>0.099565</td>\n",
       "      <td>0.803310</td>\n",
       "      <td>0.151582</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  max_word_count  max_event_id  max_up_time  sum_action_time  \\\n",
       "0  001519c8           256.0        2557.0     1801.969          297.243   \n",
       "1  0022f953           323.0        2454.0     1788.969          275.391   \n",
       "2  0042269b           404.0        4136.0     1771.669          421.201   \n",
       "3  0059420b           206.0        1556.0     1404.469          189.596   \n",
       "4  0075873a           252.0        2531.0     1662.472          313.702   \n",
       "\n",
       "   max_cursor_position  word_per_event  word_per_action_time  \\\n",
       "0               1539.0        0.100117              0.861248   \n",
       "1               1676.0        0.131622              1.172878   \n",
       "2               2291.0        0.097679              0.959162   \n",
       "3               1047.0        0.132391              1.086521   \n",
       "4               1402.0        0.099565              0.803310   \n",
       "\n",
       "   word_per_total_time  score  \n",
       "0             0.142067    3.5  \n",
       "1             0.180551    3.5  \n",
       "2             0.228034    6.0  \n",
       "3             0.146675    2.0  \n",
       "4             0.151582    4.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classification_score_features_all(df):\n",
    "    def generate_features(group):\n",
    "        features = {}\n",
    "        features['max_word_count'] = group['word_count'].max()\n",
    "        features['max_event_id'] = group['event_id'].max()\n",
    "        features['max_up_time'] = group['up_time'].max()\n",
    "        features['sum_action_time'] = group['action_time'].sum()\n",
    "        features['max_cursor_position'] = group['cursor_position'].max()\n",
    "        features['word_per_event'] = features['max_word_count'] / features['max_event_id']\n",
    "        features['word_per_action_time'] = features['max_word_count'] / features['sum_action_time']\n",
    "        features['word_per_total_time'] = features['max_word_count'] / features['max_up_time']\n",
    "        return pd.Series(features)\n",
    "    return df.groupby('id').apply(generate_features)\n",
    "\n",
    "feats = pd.DataFrame({'id': train_logs['id'].unique().tolist()})\n",
    "\n",
    "tmp_df = classification_score_features_all(train_logs)\n",
    "feats = feats.merge(tmp_df, on='id', how='left')\n",
    "feats = feats.merge(train_scores, on='id', how='left')\n",
    "feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>max_word_count</th>\n",
       "      <th>max_event_id</th>\n",
       "      <th>max_up_time</th>\n",
       "      <th>sum_action_time</th>\n",
       "      <th>max_cursor_position</th>\n",
       "      <th>word_per_event</th>\n",
       "      <th>word_per_action_time</th>\n",
       "      <th>word_per_total_time</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>256.0</td>\n",
       "      <td>2557.0</td>\n",
       "      <td>1801.969</td>\n",
       "      <td>297.243</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>0.100117</td>\n",
       "      <td>0.861248</td>\n",
       "      <td>0.142067</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022f953</td>\n",
       "      <td>323.0</td>\n",
       "      <td>2454.0</td>\n",
       "      <td>1788.969</td>\n",
       "      <td>275.391</td>\n",
       "      <td>1676.0</td>\n",
       "      <td>0.131622</td>\n",
       "      <td>1.172878</td>\n",
       "      <td>0.180551</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0042269b</td>\n",
       "      <td>404.0</td>\n",
       "      <td>4136.0</td>\n",
       "      <td>1771.669</td>\n",
       "      <td>421.201</td>\n",
       "      <td>2291.0</td>\n",
       "      <td>0.097679</td>\n",
       "      <td>0.959162</td>\n",
       "      <td>0.228034</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0059420b</td>\n",
       "      <td>206.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>1404.469</td>\n",
       "      <td>189.596</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>0.132391</td>\n",
       "      <td>1.086521</td>\n",
       "      <td>0.146675</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0075873a</td>\n",
       "      <td>252.0</td>\n",
       "      <td>2531.0</td>\n",
       "      <td>1662.472</td>\n",
       "      <td>313.702</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>0.099565</td>\n",
       "      <td>0.803310</td>\n",
       "      <td>0.151582</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  max_word_count  max_event_id  max_up_time  sum_action_time  \\\n",
       "0  001519c8           256.0        2557.0     1801.969          297.243   \n",
       "1  0022f953           323.0        2454.0     1788.969          275.391   \n",
       "2  0042269b           404.0        4136.0     1771.669          421.201   \n",
       "3  0059420b           206.0        1556.0     1404.469          189.596   \n",
       "4  0075873a           252.0        2531.0     1662.472          313.702   \n",
       "\n",
       "   max_cursor_position  word_per_event  word_per_action_time  \\\n",
       "0               1539.0        0.100117              0.861248   \n",
       "1               1676.0        0.131622              1.172878   \n",
       "2               2291.0        0.097679              0.959162   \n",
       "3               1047.0        0.132391              1.086521   \n",
       "4               1402.0        0.099565              0.803310   \n",
       "\n",
       "   word_per_total_time  score  \n",
       "0             0.142067      6  \n",
       "1             0.180551      6  \n",
       "2             0.228034     11  \n",
       "3             0.146675      3  \n",
       "4             0.151582      7  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_score_to_class(score):\n",
    "    return int(score / 0.5) - 1\n",
    "\n",
    "feats['score'] = feats['score'].apply(convert_score_to_class)\n",
    "feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2471, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats = feats.copy()\n",
    "train_feats['score'] = train_feats['score'].astype('category')\n",
    "target_col = 'score'\n",
    "drop_cols = 'id'\n",
    "train_cols = [col for col in train_feats.columns if col not in target_col + drop_cols]\n",
    "train_feats.head()\n",
    "train_feats.dtypes\n",
    "train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_feats['score'].value_counts().sort_index().plot(kind=\"barh\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 1\n",
    "# SPLIT = 10\n",
    "\n",
    "# model_dict = {}\n",
    "# scores = []\n",
    "# preds = np.zeros((len(train_feats), 1))\n",
    "\n",
    "# # best_params = {\n",
    "# #     'reg_alpha': 0.6016917340618352, \n",
    "# #     'reg_lambda': 3.8071290717767194, \n",
    "# #     'colsample_bytree': 0.45216556596658897, \n",
    "# #     'subsample': 0.4832292138435902, \n",
    "# #     'learning_rate': 0.001,\n",
    "# #     'num_leaves': 11, \n",
    "# #     'max_depth': 27, \n",
    "# #     'min_child_samples': 17,\n",
    "# #     'n_jobs': 4\n",
    "# # }\n",
    "\n",
    "# for i in range(EPOCHS):\n",
    "#     kf = model_selection.KFold(n_splits=SPLIT, random_state=42 + i * 10, shuffle=True)\n",
    "#     valid_preds = np.zeros(train_feats.shape[0])\n",
    "    \n",
    "#     for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "#         print(f'Epoch: {i + 1} Fold: {fold + 1}')\n",
    "#         X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "#         X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "#         print(len(np.unique(y_train)))\n",
    "        \n",
    "#         params = {\n",
    "#             \"objective\": \"binary\" if len(np.unique(y_train)) == 2 else \"multiclass\",\n",
    "#             \"metric\": \"binary_logloss\" if len(np.unique(y_train)) == 2 else \"multi_logloss\",\n",
    "#             \"random_state\": 42,\n",
    "#             \"n_estimators\": 11_861,\n",
    "#             \"verbosity\": -1,\n",
    "#             # **best_params\n",
    "#         }\n",
    "\n",
    "#         model = lgb.LGBMClassifier(**params)\n",
    "#         early_stopping_callback = lgb.early_stopping(100, verbose=True)\n",
    "        \n",
    "#         model.fit(\n",
    "#             X_train, y_train,\n",
    "#             eval_set=[(X_valid, y_valid)],\n",
    "#             callbacks=[early_stopping_callback]\n",
    "#         )\n",
    "        \n",
    "#         valid_predict = model.predict(X_valid)\n",
    "#         valid_preds[valid_idx] = valid_predict\n",
    "#         preds[valid_idx, 0] += valid_predict\n",
    "        \n",
    "#         score = metrics.accuracy_score(y_valid, valid_predict)\n",
    "#         model_dict[f'Epoch{i + 1}-Fold{fold + 1}'] = model\n",
    "        \n",
    "#     final_score = metrics.accuracy_score(train_feats[target_col], valid_preds)\n",
    "#     scores.append(final_score)\n",
    "    \n",
    "# print(\"Avg Acc:\", np.mean(scores))\n",
    "\n",
    "# print('metric LGBM = {:.5f}'.format(metrics.accuracy_score(train_feats[target_col], preds[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1725, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats['score'] = train_feats['score'].astype(float)\n",
    "train_feats = train_feats[(train_feats['score'] >= 5) & (train_feats['score'] <= 8)]\n",
    "train_feats['score'] = train_feats['score'] - 5\n",
    "train_feats['score'] = train_feats['score'].astype('category')\n",
    "train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.56000000e+02 2.55700000e+03 1.80196900e+03 2.97243000e+02\n",
      " 1.53900000e+03 1.00117325e-01 8.61248204e-01 1.42066817e-01]\n",
      "(1725, 8) (1725,)\n",
      "{0: 1.2834821428571428, 1: 0.8873456790123457, 2: 0.8607784431137725, 3: 1.0727611940298507}\n",
      "[0. 1. 2. 3.]\n",
      "Training on fold 1...\n",
      "Epoch 1/200\n",
      "44/44 [==============================] - 1s 6ms/step - loss: 62.2221 - accuracy: 0.2616 - val_loss: 12.4270 - val_accuracy: 0.3826\n",
      "Epoch 2/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 8.1016 - accuracy: 0.3486 - val_loss: 4.7558 - val_accuracy: 0.4377\n",
      "Epoch 3/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 3.8310 - accuracy: 0.3623 - val_loss: 2.5874 - val_accuracy: 0.3710\n",
      "Epoch 4/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 2.3577 - accuracy: 0.3739 - val_loss: 2.0834 - val_accuracy: 0.3420\n",
      "Epoch 5/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.8542 - accuracy: 0.3355 - val_loss: 1.7894 - val_accuracy: 0.3478\n",
      "Epoch 6/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.6416 - accuracy: 0.3420 - val_loss: 1.6366 - val_accuracy: 0.4232\n",
      "Epoch 7/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.5906 - accuracy: 0.3493 - val_loss: 1.4443 - val_accuracy: 0.3536\n",
      "Epoch 8/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.4032 - accuracy: 0.3616 - val_loss: 1.4227 - val_accuracy: 0.3217\n",
      "Epoch 9/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3944 - accuracy: 0.3304 - val_loss: 1.3568 - val_accuracy: 0.3507\n",
      "Epoch 10/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3108 - accuracy: 0.3558 - val_loss: 1.3388 - val_accuracy: 0.3478\n",
      "Epoch 11/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2964 - accuracy: 0.3746 - val_loss: 1.3921 - val_accuracy: 0.3623\n",
      "Epoch 12/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3216 - accuracy: 0.3659 - val_loss: 1.4201 - val_accuracy: 0.3275\n",
      "Epoch 13/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2900 - accuracy: 0.3710 - val_loss: 1.3101 - val_accuracy: 0.3768\n",
      "Epoch 14/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3766 - accuracy: 0.3638 - val_loss: 1.3325 - val_accuracy: 0.3768\n",
      "Epoch 15/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2912 - accuracy: 0.3761 - val_loss: 1.2766 - val_accuracy: 0.4406\n",
      "Epoch 16/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2901 - accuracy: 0.3739 - val_loss: 1.2938 - val_accuracy: 0.4174\n",
      "Epoch 17/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2644 - accuracy: 0.3797 - val_loss: 1.2676 - val_accuracy: 0.4435\n",
      "Epoch 18/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2661 - accuracy: 0.3841 - val_loss: 1.3007 - val_accuracy: 0.3884\n",
      "Epoch 19/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.2466 - accuracy: 0.3971 - val_loss: 1.4735 - val_accuracy: 0.2899\n",
      "Epoch 20/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2730 - accuracy: 0.3768 - val_loss: 1.2564 - val_accuracy: 0.3942\n",
      "Epoch 21/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2774 - accuracy: 0.3732 - val_loss: 1.8489 - val_accuracy: 0.2609\n",
      "Epoch 22/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3939 - accuracy: 0.3732 - val_loss: 1.4353 - val_accuracy: 0.3623\n",
      "Epoch 23/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3069 - accuracy: 0.3616 - val_loss: 1.3315 - val_accuracy: 0.3159\n",
      "Epoch 24/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2582 - accuracy: 0.3906 - val_loss: 1.3565 - val_accuracy: 0.3739\n",
      "Epoch 25/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2838 - accuracy: 0.3812 - val_loss: 1.2617 - val_accuracy: 0.4087\n",
      "Epoch 26/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2594 - accuracy: 0.3877 - val_loss: 1.5114 - val_accuracy: 0.3565\n",
      "Epoch 27/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3353 - accuracy: 0.3572 - val_loss: 1.3252 - val_accuracy: 0.3768\n",
      "Epoch 28/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3116 - accuracy: 0.3681 - val_loss: 1.2674 - val_accuracy: 0.4203\n",
      "Epoch 29/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.3062 - accuracy: 0.3783 - val_loss: 1.3007 - val_accuracy: 0.3855\n",
      "Epoch 30/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2776 - accuracy: 0.3862 - val_loss: 1.2926 - val_accuracy: 0.4116\n",
      "Epoch 31/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2486 - accuracy: 0.3674 - val_loss: 1.3577 - val_accuracy: 0.3130\n",
      "Epoch 32/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2641 - accuracy: 0.3862 - val_loss: 1.2842 - val_accuracy: 0.3623\n",
      "Epoch 33/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2338 - accuracy: 0.4181 - val_loss: 1.2998 - val_accuracy: 0.4116\n",
      "Epoch 34/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2663 - accuracy: 0.3761 - val_loss: 1.2635 - val_accuracy: 0.4261\n",
      "Epoch 35/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2256 - accuracy: 0.4203 - val_loss: 1.2690 - val_accuracy: 0.4232\n",
      "Epoch 36/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.2923 - accuracy: 0.3978 - val_loss: 1.3199 - val_accuracy: 0.4029\n",
      "Epoch 37/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2542 - accuracy: 0.3732 - val_loss: 1.2668 - val_accuracy: 0.4725\n",
      "Epoch 38/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2586 - accuracy: 0.3783 - val_loss: 1.3027 - val_accuracy: 0.3826\n",
      "Epoch 39/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2666 - accuracy: 0.4022 - val_loss: 1.2612 - val_accuracy: 0.4493\n",
      "Epoch 40/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2491 - accuracy: 0.3964 - val_loss: 1.3096 - val_accuracy: 0.4029\n",
      "Epoch 41/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2801 - accuracy: 0.3826 - val_loss: 1.2866 - val_accuracy: 0.4406\n",
      "Epoch 42/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2626 - accuracy: 0.3841 - val_loss: 1.2614 - val_accuracy: 0.4435\n",
      "Epoch 43/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2411 - accuracy: 0.3942 - val_loss: 1.2604 - val_accuracy: 0.4522\n",
      "Epoch 44/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2401 - accuracy: 0.4130 - val_loss: 1.2743 - val_accuracy: 0.4464\n",
      "Epoch 45/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2525 - accuracy: 0.3848 - val_loss: 1.2611 - val_accuracy: 0.4435\n",
      "Epoch 46/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2242 - accuracy: 0.4188 - val_loss: 1.2548 - val_accuracy: 0.4290\n",
      "Epoch 47/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2141 - accuracy: 0.4341 - val_loss: 1.4001 - val_accuracy: 0.3304\n",
      "Epoch 48/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2947 - accuracy: 0.3710 - val_loss: 1.2493 - val_accuracy: 0.4522\n",
      "Epoch 49/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2371 - accuracy: 0.4014 - val_loss: 1.2853 - val_accuracy: 0.4290\n",
      "Epoch 50/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2478 - accuracy: 0.4022 - val_loss: 1.3102 - val_accuracy: 0.3826\n",
      "Epoch 51/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2403 - accuracy: 0.4029 - val_loss: 1.3153 - val_accuracy: 0.3855\n",
      "Epoch 52/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.2384 - accuracy: 0.4014 - val_loss: 1.2931 - val_accuracy: 0.3971\n",
      "Epoch 53/200\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 1.2743 - accuracy: 0.3623 - val_loss: 1.2838 - val_accuracy: 0.4116\n",
      "Epoch 54/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2329 - accuracy: 0.3964 - val_loss: 1.2595 - val_accuracy: 0.4203\n",
      "Epoch 55/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.2373 - accuracy: 0.4072 - val_loss: 1.2893 - val_accuracy: 0.4203\n",
      "Epoch 56/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.2381 - accuracy: 0.3819 - val_loss: 1.2525 - val_accuracy: 0.4261\n",
      "Epoch 57/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2333 - accuracy: 0.3935 - val_loss: 1.2677 - val_accuracy: 0.4406\n",
      "Epoch 58/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2672 - accuracy: 0.3891 - val_loss: 1.3508 - val_accuracy: 0.3594\n",
      "Epoch 59/200\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 1.2246 - accuracy: 0.4159 - val_loss: 1.2722 - val_accuracy: 0.4319\n",
      "Epoch 60/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2460 - accuracy: 0.3942 - val_loss: 1.2746 - val_accuracy: 0.4029\n",
      "Epoch 61/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2552 - accuracy: 0.3754 - val_loss: 1.3346 - val_accuracy: 0.3565\n",
      "Epoch 62/200\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 1.2308 - accuracy: 0.4123 - val_loss: 1.2924 - val_accuracy: 0.3942\n",
      "Epoch 63/200\n",
      "33/44 [=====================>........] - ETA: 0s - loss: 1.2289 - accuracy: 0.3864"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y_categorical[train_index], y_categorical[test_index]\n\u001b[0;32m     40\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model((\u001b[38;5;241m8\u001b[39m,))\n\u001b[1;32m---> 42\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# class_weight=class_weights, \u001b[39;49;00m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:1832\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1818\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1819\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1830\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[0;32m   1831\u001b[0m     )\n\u001b[1;32m-> 1832\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1834\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1835\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1837\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1841\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1843\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1844\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1847\u001b[0m }\n\u001b[0;32m   1848\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:2261\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_tune_steps_per_execution:\n\u001b[0;32m   2260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_tuner\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m-> 2261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[0;32m   2262\u001b[0m     _,\n\u001b[0;32m   2263\u001b[0m     dataset_or_iterator,\n\u001b[0;32m   2264\u001b[0m ) \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m   2266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1341\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1341\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1342\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[0;32m   1343\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:496\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    495\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:705\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    701\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    704\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 705\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:744\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    741\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    742\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[0;32m    743\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 744\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\86183\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3451\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3450\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3451\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3452\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3454\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = train_feats[train_cols]\n",
    "y = train_feats[target_col]\n",
    "X = X.to_numpy() if isinstance(X, pd.DataFrame) else X\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "print(X[0])\n",
    "y = y.to_numpy() if isinstance(y, pd.DataFrame) else y\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "y_categorical = to_categorical(y)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(class_weights)\n",
    "print(np.unique(y))\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    fold += 1\n",
    "    print(f\"Training on fold {fold}...\")\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_categorical[train_index], y_categorical[test_index]\n",
    "    \n",
    "    model = create_model((8,))\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        # class_weight=class_weights, \n",
    "        epochs=200, \n",
    "        batch_size=32, \n",
    "        validation_data=(X_test, y_test)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
